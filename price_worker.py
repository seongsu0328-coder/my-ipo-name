import os
import json
import requests
import pandas as pd
import numpy as np
import yfinance as yf
from datetime import datetime
import time  
import pytz 
from supabase import create_client

# [1] í™˜ê²½ ì„¤ì •
SUPABASE_URL = os.environ.get("SUPABASE_URL", "").rstrip('/')
# URL ë³´ì •
if "/rest/v1" in SUPABASE_URL:
    SUPABASE_URL = SUPABASE_URL.split("/rest/v1")[0]

SUPABASE_KEY = os.environ.get("SUPABASE_KEY", "")

if SUPABASE_URL and SUPABASE_KEY:
    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
else:
    print("âŒ Supabase í™˜ê²½ë³€ìˆ˜ ëˆ„ë½"); exit()

# [2] í‘œì¤€ ì—”ì§„
def sanitize_value(v):
    if v is None or pd.isna(v): return None
    if isinstance(v, (np.floating, float)):
        return float(v) if not (np.isinf(v) or np.isnan(v)) else 0.0
    if isinstance(v, (np.integer, int)): return int(v)
    return str(v).strip().replace('\x00', '')

def batch_upsert(table_name, data_list, on_conflict="ticker"):
    if not data_list: return False
    endpoint = f"{SUPABASE_URL}/rest/v1/{table_name}?on_conflict={on_conflict}"
    headers = {
        "apikey": SUPABASE_KEY,
        "Authorization": f"Bearer {SUPABASE_KEY}",
        "Content-Type": "application/json",
        "Prefer": "resolution=merge-duplicates"
    }
    clean_batch = []
    for item in data_list:
        payload = {k: sanitize_value(v) for k, v in item.items()}
        if payload.get(on_conflict): clean_batch.append(payload)

    if not clean_batch: return False
    
    try:
        # ğŸš¨ [í•µì‹¬ 1] timeout=10 ì„ ì¶”ê°€í•˜ì—¬ ë¬´í•œ ëŒ€ê¸°(í”„ë¦¬ì§•) í˜„ìƒ ì›ì²œ ì°¨ë‹¨!
        resp = requests.post(endpoint, json=clean_batch, headers=headers, timeout=10)
        
        if resp.status_code not in [200, 201, 204]:
            print(f"âŒ [{table_name}] ì‹¤íŒ¨ ({resp.status_code}): {resp.text[:200]}", flush=True) 
            return False
        return True
    except Exception as e: 
        print(f"âŒ í†µì‹  ì—ëŸ¬ (Timeout ë“±): {e}", flush=True)
        return False

# [3] ë¡œì§ í•¨ìˆ˜
def get_target_tickers():
    try:
        res = supabase.table("stock_cache").select("symbol").execute()
        return [item['symbol'] for item in res.data] if res.data else []
    except Exception as e:
        print(f"âš ï¸ í‹°ì»¤ ëª©ë¡ ë¡œë“œ ì‹¤íŒ¨: {e}", flush=True)
        return []

def fetch_and_update_prices():
    print(f"ğŸš€ ì£¼ê°€ ìˆ˜ì§‘ ì‹œì‘ (ET: {datetime.now().strftime('%H:%M')})", flush=True)
    tickers = get_target_tickers()
    if not tickers: 
        print("ëŒ€ìƒ ì¢…ëª© ì—†ìŒ", flush=True); return

    print(f"ëŒ€ìƒ ì¢…ëª©: {len(tickers)}ê°œ -> ë‹¤ìš´ë¡œë“œ ì‹œì‘", flush=True)
    
    try:
        # yfinance ì—ëŸ¬ê°€ ë¡œê·¸ë¥¼ ë„ˆë¬´ ë§ì´ ì°¨ì§€í•˜ëŠ” ê²ƒì„ ë§‰ê¸° ìœ„í•´ ì˜µì…˜ ì¡°ì •
        data = yf.download(tickers, period="1d", interval="1m", group_by='ticker', threads=True, progress=False)
    except Exception as e:
        print(f"âš ï¸ ë‹¤ìš´ë¡œë“œ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}", flush=True)
        return

    upsert_list = []
    now_iso = datetime.now(pytz.timezone('Asia/Seoul')).isoformat() 
    is_multi = len(tickers) > 1
    
    for symbol in tickers:
        try:
            if is_multi:
                if symbol not in data: continue
                closes = data[symbol]['Close']
            else:
                closes = data['Close']
            
            valid_closes = closes.dropna()
            if valid_closes.empty: continue
            
            last_price = valid_closes.iloc[-1]
            
            if last_price > 0:
                upsert_list.append({"ticker": symbol, "price": float(last_price), "updated_at": now_iso})
        except: continue 
    
    if upsert_list:
        # ğŸš¨ [í•µì‹¬ 2] flush=True ë¥¼ ë„£ì–´ GitHub Actionsì—ì„œ ê¸€ì”¨ê°€ ì¦‰ì‹œ ëœ¨ê²Œ ë§Œë“¦
        print(f"ğŸ“Š {len(upsert_list)}ê°œ ì¢…ëª© ë°ì´í„° í™•ë³´. DB ì €ì¥ ì‹œë„...", flush=True)
        
        chunk_size = 50
        success_count = 0
        
        for i in range(0, len(upsert_list), chunk_size):
            chunk = upsert_list[i : i + chunk_size]
            try:
                is_success = batch_upsert("price_cache", chunk, on_conflict="ticker")
                if is_success:
                    success_count += len(chunk)
                    print(f"  -> {success_count}/{len(upsert_list)}ê°œ ì €ì¥ ì™„ë£Œ...", flush=True)
                time.sleep(1.0) # í˜¹ì‹œ ëª¨ë¥¼ ì„œë²„ ë¶€í•˜ë¥¼ ë§‰ê¸° ìœ„í•´ 1ì´ˆ íœ´ì‹
            except Exception as e:
                print(f"âŒ ì²­í¬ ì €ì¥ ì¤‘ ì—ëŸ¬: {e}", flush=True)
            
        print("âœ… ì£¼ê°€ ìºì‹± ì „ì†¡ ì™„ë£Œ!", flush=True)
        
        try:
            heartbeat_payload = [{
                "cache_key": "WORKER_LAST_RUN",
                "content": '{"status": "alive", "worker": "price_worker"}',
                "updated_at": now_iso
            }]
            batch_upsert("analysis_cache", heartbeat_payload, on_conflict="cache_key")
            print(f"ğŸ“¡ ë©”ì¸ ì•± ìƒì¡´ ì‹ ê³  ì™„ë£Œ (KST): {now_iso}", flush=True)
        except Exception as e:
            print(f"âš ï¸ ìƒì¡´ ì‹ ê³  ì‹¤íŒ¨: {e}", flush=True)
            
    else:
        print("âš ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.", flush=True)

if __name__ == "__main__":
    fetch_and_update_prices()
