import os
import json
import requests
import pandas as pd
import numpy as np
import yfinance as yf
from datetime import datetime
import time  
import pytz 

# [1] í™˜ê²½ ì„¤ì •
SUPABASE_URL = os.environ.get("SUPABASE_URL", "").rstrip('/')
# URL ë³´ì • (https://xyz.supabase.co í˜•íƒœì—¬ì•¼ í•¨)
if "/rest/v1" in SUPABASE_URL:
    SUPABASE_URL = SUPABASE_URL.split("/rest/v1")[0]

SUPABASE_KEY = os.environ.get("SUPABASE_KEY", "")

if not SUPABASE_URL or not SUPABASE_KEY:
    print("âŒ Supabase í™˜ê²½ë³€ìˆ˜ ëˆ„ë½"); exit()

# [2] ë°ì´í„° ì •ì œ í•¨ìˆ˜
def sanitize_value(v):
    if v is None or pd.isna(v): return None
    if isinstance(v, (np.floating, float)):
        return float(v) if not (np.isinf(v) or np.isnan(v)) else 0.0
    if isinstance(v, (np.integer, int)): return int(v)
    return str(v).strip().replace('\x00', '')

# [3] ğŸš€ [í•µì‹¬ ìˆ˜ì •] ê°€ì¥ ê°€ë²¼ìš´ requests ë°©ì‹ìœ¼ë¡œ DB ì „ì†¡
def batch_upsert_raw(table_name, data_list, on_conflict="ticker"):
    if not data_list: return False
    
    # Supabase REST API ì—”ë“œí¬ì¸íŠ¸
    endpoint = f"{SUPABASE_URL}/rest/v1/{table_name}?on_conflict={on_conflict}"
    
    headers = {
        "apikey": SUPABASE_KEY,
        "Authorization": f"Bearer {SUPABASE_KEY}",
        "Content-Type": "application/json",
        "Prefer": "resolution=merge-duplicates"
    }
    
    clean_batch = []
    for item in data_list:
        payload = {k: sanitize_value(v) for k, v in item.items()}
        if payload.get(on_conflict):
            clean_batch.append(payload)

    if not clean_batch: return False
    
    try:
        # ğŸš¨ timeoutì„ 15ì´ˆë¡œ ì„¤ì •í•˜ì—¬ ë¬´í•œ ëŒ€ê¸° í˜„ìƒ ì™„ì „ ì°¨ë‹¨
        resp = requests.post(endpoint, json=clean_batch, headers=headers, timeout=15)
        if resp.status_code in [200, 201, 204]:
            return True
        else:
            print(f"âŒ DB ì „ì†¡ ì‹¤íŒ¨ ({resp.status_code}): {resp.text[:100]}", flush=True)
            return False
    except Exception as e: 
        print(f"âŒ í†µì‹  ì—ëŸ¬: {e}", flush=True)
        return False

# [4] í‹°ì»¤ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (requests ë°©ì‹)
def get_target_tickers():
    endpoint = f"{SUPABASE_URL}/rest/v1/stock_cache?select=symbol"
    headers = {"apikey": SUPABASE_KEY, "Authorization": f"Bearer {SUPABASE_KEY}"}
    try:
        resp = requests.get(endpoint, headers=headers, timeout=10)
        if resp.status_code == 200:
            return [item['symbol'] for item in resp.json()]
        return []
    except:
        return []

def fetch_and_update_prices():
    print(f"ğŸš€ ì£¼ê°€ ìˆ˜ì§‘ ì‹œì‘ (KST: {datetime.now(pytz.timezone('Asia/Seoul')).strftime('%H:%M')})", flush=True)
    tickers = get_target_tickers()
    if not tickers: 
        print("ëŒ€ìƒ ì¢…ëª© ì—†ìŒ", flush=True); return

    print(f"ëŒ€ìƒ ì¢…ëª©: {len(tickers)}ê°œ -> ë‹¤ìš´ë¡œë“œ ì‹œì‘", flush=True)
    
    try:
        # ğŸš¨ interval ì‚­ì œ ìœ ì§€
        data = yf.download(tickers, period="1d", group_by='ticker', threads=True, progress=False)
    except Exception as e:
        print(f"âš ï¸ ë‹¤ìš´ë¡œë“œ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}", flush=True); return

    upsert_list = []
    now_iso = datetime.now(pytz.timezone('Asia/Seoul')).isoformat() 
    is_multi = len(tickers) > 1
    
    for symbol in tickers:
        try:
            closes = data[symbol]['Close'] if is_multi else data['Close']
            valid_closes = closes.dropna()
            if not valid_closes.empty and float(valid_closes.iloc[-1]) > 0:
                upsert_list.append({
                    "ticker": str(symbol), 
                    "price": float(valid_closes.iloc[-1]), 
                    "updated_at": now_iso
                })
        except: continue 
    
    if upsert_list:
        print(f"ğŸ“Š {len(upsert_list)}ê°œ ì¢…ëª© ë°ì´í„° í™•ë³´. DB ì €ì¥ ì‹œë„...", flush=True)
        
        chunk_size = 50
        success_count = 0
        
        for i in range(0, len(upsert_list), chunk_size):
            chunk = upsert_list[i : i + chunk_size]
            if batch_upsert_raw("price_cache", chunk, on_conflict="ticker"):
                success_count += len(chunk)
                print(f"  -> {success_count}/{len(upsert_list)}ê°œ ì €ì¥ ì™„ë£Œ...", flush=True)
            time.sleep(1.0) # ì•ˆì „ì„ ìœ„í•´ 1ì´ˆ íœ´ì‹
            
        print("âœ… ì£¼ê°€ ìºì‹± ì „ì†¡ ì™„ë£Œ!", flush=True)
        
        # ğŸ“¡ ë©”ì¸ ì•± ìƒì¡´ ì‹ ê³ 
        heartbeat = [{
            "cache_key": "WORKER_LAST_RUN",
            "content": "alive",
            "updated_at": now_iso
        }]
        batch_upsert_raw("analysis_cache", heartbeat, on_conflict="cache_key")
        print(f"ğŸ“¡ ìƒì¡´ ì‹ ê³  ì™„ë£Œ: {now_iso}", flush=True)
            
    else:
        print("âš ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.", flush=True)

if __name__ == "__main__":
    fetch_and_update_prices()
