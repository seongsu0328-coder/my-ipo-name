import os
import json
import requests
import pandas as pd
import numpy as np
import yfinance as yf
from datetime import datetime
import time  # ì²­í¬ ë”œë ˆì´ë¥¼ ìœ„í•´ ì¶”ê°€
import pytz 
from supabase import create_client

# [1] í™˜ê²½ ì„¤ì •
SUPABASE_URL = os.environ.get("SUPABASE_URL", "").rstrip('/')
# URL ë³´ì •
if "/rest/v1" in SUPABASE_URL:
    SUPABASE_URL = SUPABASE_URL.split("/rest/v1")[0]

SUPABASE_KEY = os.environ.get("SUPABASE_KEY", "")

if SUPABASE_URL and SUPABASE_KEY:
    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
else:
    print("âŒ Supabase í™˜ê²½ë³€ìˆ˜ ëˆ„ë½"); exit()

# [2] í‘œì¤€ ì—”ì§„
def sanitize_value(v):
    if v is None or pd.isna(v): return None
    if isinstance(v, (np.floating, float)):
        return float(v) if not (np.isinf(v) or np.isnan(v)) else 0.0
    if isinstance(v, (np.integer, int)): return int(v)
    return str(v).strip().replace('\x00', '')

def batch_upsert(table_name, data_list, on_conflict="ticker"):
    if not data_list: return False
    endpoint = f"{SUPABASE_URL}/rest/v1/{table_name}?on_conflict={on_conflict}"
    headers = {
        "apikey": SUPABASE_KEY,
        "Authorization": f"Bearer {SUPABASE_KEY}",
        "Content-Type": "application/json",
        "Prefer": "resolution=merge-duplicates"
    }
    clean_batch = []
    for item in data_list:
        payload = {k: sanitize_value(v) for k, v in item.items()}
        if payload.get(on_conflict): clean_batch.append(payload)

    if not clean_batch: return False
    
    try:
        resp = requests.post(endpoint, json=clean_batch, headers=headers)
        if resp.status_code not in [200, 201, 204]:
            print(f"âŒ [{table_name}] ì‹¤íŒ¨ ({resp.status_code}): {resp.text[:200]}") # ì—ëŸ¬ ë‚´ìš© í™•ì¸
            return False
        return True
    except Exception as e: 
        print(f"âŒ í†µì‹  ì—ëŸ¬: {e}")
        return False

# [3] ë¡œì§ í•¨ìˆ˜
def get_target_tickers():
    try:
        # stock_cacheê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        res = supabase.table("stock_cache").select("symbol").execute()
        return [item['symbol'] for item in res.data] if res.data else []
    except Exception as e:
        print(f"âš ï¸ í‹°ì»¤ ëª©ë¡ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return []

def fetch_and_update_prices():
    print(f"ğŸš€ ì£¼ê°€ ìˆ˜ì§‘ ì‹œì‘ (ET: {datetime.now().strftime('%H:%M')})")
    tickers = get_target_tickers()
    if not tickers: print("ëŒ€ìƒ ì¢…ëª© ì—†ìŒ"); return

    print(f"ëŒ€ìƒ ì¢…ëª©: {len(tickers)}ê°œ -> ë‹¤ìš´ë¡œë“œ ì‹œì‘")
    
    # yfinance ì—ëŸ¬ ë©”ì‹œì§€ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ threads=Falseë¡œ í•˜ê±°ë‚˜ quiet=True ì‹œë„
    # ignore_tz=Trueë¡œ íƒ€ì„ì¡´ ê²½ê³  ë¬´ì‹œ
    try:
        data = yf.download(tickers, period="1d", interval="1m", group_by='ticker', threads=True, progress=False)
    except Exception as e:
        print(f"âš ï¸ ë‹¤ìš´ë¡œë“œ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        return

    upsert_list = []
    now_iso = datetime.now(pytz.timezone('Asia/Seoul')).isoformat() 
    
    # ë°ì´í„° êµ¬ì¡°ê°€ 1ê°œì¼ ë•Œì™€ ì—¬ëŸ¬ ê°œì¼ ë•Œ ë‹¤ë¦„
    is_multi = len(tickers) > 1
    
    for symbol in tickers:
        try:
            if is_multi:
                if symbol not in data: continue
                closes = data[symbol]['Close']
            else:
                closes = data['Close']
            
            # ìœ íš¨í•œ ë°ì´í„°ë§Œ ì¶”ì¶œ
            valid_closes = closes.dropna()
            if valid_closes.empty: continue
            
            last_price = valid_closes.iloc[-1]
            
            if last_price > 0:
                upsert_list.append({"ticker": symbol, "price": float(last_price), "updated_at": now_iso})
        except: continue # ê°œë³„ ì—ëŸ¬ ë¬´ì‹œ
    
    if upsert_list:
        print(f"ğŸ“Š {len(upsert_list)}ê°œ ì¢…ëª© ë°ì´í„° í™•ë³´. DB ì €ì¥ ì‹œë„...")
        
        # ğŸš¨ [í•µì‹¬ ìˆ˜ì •] ë°ì´í„°ë¥¼ 50ê°œ ë‹¨ìœ„ë¡œ ìª¼ê°œì„œ ì—…ë¡œë“œ (ì„œë²„ ê³¼ë¶€í•˜ ì°¨ë‹¨)
        chunk_size = 50
        success_count = 0
        
        for i in range(0, len(upsert_list), chunk_size):
            chunk = upsert_list[i : i + chunk_size]
            
            is_success = batch_upsert("price_cache", chunk, on_conflict="ticker")
            
            if is_success:
                success_count += len(chunk)
                print(f"  -> {success_count}/{len(upsert_list)}ê°œ ì €ì¥ ì™„ë£Œ...")
            
            # ë„ˆë¬´ ë¹ ë¥¸ ìš”ì²­ìœ¼ë¡œ ì¸í•œ Rate Limit íšŒí”¼
            time.sleep(0.5)
            
        print("âœ… ì£¼ê°€ ìºì‹± ì „ì†¡ ì™„ë£Œ!")
        
        # ğŸ“¡ [ìƒì¡´ ì‹ ê³  ë¡œì§ ì¶”ê°€] ì•±(app.py)ì˜ "âœ… ë°ì´í„° ì •ìƒ" ë°°ì§€ë¥¼ í™œì„±í™”í•˜ê¸° ìœ„í•œ ê¸°ë¡
        try:
            heartbeat_payload = [{
                "cache_key": "WORKER_LAST_RUN",
                "content": '{"status": "alive", "worker": "price_worker"}',
                "updated_at": now_iso
            }]
            batch_upsert("analysis_cache", heartbeat_payload, on_conflict="cache_key")
            print(f"ğŸ“¡ ë©”ì¸ ì•± ìƒì¡´ ì‹ ê³  ì™„ë£Œ (KST): {now_iso}")
        except Exception as e:
            print(f"âš ï¸ ìƒì¡´ ì‹ ê³  ì‹¤íŒ¨: {e}")
            
    else:
        print("âš ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    fetch_and_update_prices()
