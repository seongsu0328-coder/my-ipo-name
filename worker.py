import os
import time
import json
import re
import requests
import pandas as pd
import numpy as np
import yfinance as yf
import logging
from datetime import datetime, timedelta

from supabase import create_client
import google.generativeai as genai

# ==========================================
# [1] í™˜ê²½ ì„¤ì •
# ==========================================
raw_url = os.environ.get("SUPABASE_URL", "")
if "/rest/v1" in raw_url:
    SUPABASE_URL = raw_url.split("/rest/v1")[0].rstrip('/')
else:
    SUPABASE_URL = raw_url.rstrip('/')

SUPABASE_KEY = os.environ.get("SUPABASE_KEY", "")
GENAI_API_KEY = os.environ.get("GENAI_API_KEY", "")
FINNHUB_API_KEY = os.environ.get("FINNHUB_API_KEY", "")

logging.getLogger('yfinance').setLevel(logging.CRITICAL)

if not (SUPABASE_URL and SUPABASE_KEY):
    print("âŒ í™˜ê²½ë³€ìˆ˜ ëˆ„ë½")
    exit()

try:
    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
except Exception as e:
    print(f"âŒ Supabase ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    exit()

# ëª¨ë¸ ì´ì›í™”
search_model = None   
standard_model = None 

if GENAI_API_KEY:
    genai.configure(api_key=GENAI_API_KEY)
    try:
        search_model = genai.GenerativeModel('gemini-2.0-flash', tools=[{'google_search_retrieval': {}}])
        standard_model = genai.GenerativeModel('gemini-2.0-flash')
        print("âœ… AI ëª¨ë¸ ë¡œë“œ ì„±ê³µ (Search / Standard ì´ì›í™”)")
    except Exception as e:
        print(f"âŒ AI ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")

SUPPORTED_LANGS = ['ko', 'en', 'ja', 'zh']

# ==========================================
# [2] í—¬í¼ í•¨ìˆ˜
# ==========================================
def sanitize_value(v):
    if v is None or pd.isna(v): return None
    if isinstance(v, (np.floating, float)): return float(v) if not (np.isinf(v) or np.isnan(v)) else 0.0
    if isinstance(v, (np.integer, int)): return int(v)
    if isinstance(v, (np.bool_, bool)): return bool(v)
    return str(v).strip().replace('\x00', '')

def batch_upsert(table_name, data_list, on_conflict="ticker"):
    if not data_list: return
    endpoint = f"{SUPABASE_URL}/rest/v1/{table_name}?on_conflict={on_conflict}"
    headers = {
        "apikey": SUPABASE_KEY,
        "Authorization": f"Bearer {SUPABASE_KEY}",
        "Content-Type": "application/json",
        "Prefer": "return=minimal,resolution=merge-duplicates" 
    }
    clean_batch = []
    for item in data_list:
        payload = {k: sanitize_value(v) for k, v in item.items()}
        if payload.get(on_conflict): clean_batch.append(payload)

    if not clean_batch: return

    try:
        requests.post(endpoint, json=clean_batch, headers=headers)
    except Exception as e:
        print(f"âŒ [{table_name}] ì—…ë¡œë“œ ì—ëŸ¬: {e}")

def get_target_stocks():
    if not FINNHUB_API_KEY: return pd.DataFrame()
    now = datetime.now()
    ranges = [
        (now - timedelta(days=200), now + timedelta(days=35)), 
        (now - timedelta(days=380), now - timedelta(days=170)), 
        (now - timedelta(days=560), now - timedelta(days=350))
    ]
    all_data = []
    for start_dt, end_dt in ranges:
        url = f"https://finnhub.io/api/v1/calendar/ipo?from={start_dt.strftime('%Y-%m-%d')}&to={end_dt.strftime('%Y-%m-%d')}&token={FINNHUB_API_KEY}"
        try:
            res = requests.get(url, timeout=10).json()
            if res.get('ipoCalendar'): all_data.extend(res['ipoCalendar'])
        except: continue
        
    if not all_data: return pd.DataFrame()
    df = pd.DataFrame(all_data).dropna(subset=['symbol'])
    df['symbol'] = df['symbol'].astype(str).str.strip()
    return df.drop_duplicates(subset=['symbol'])

def get_current_prices():
    try:
        res = supabase.table("price_cache").select("ticker, price").execute()
        return {item['ticker']: float(item['price']) for item in res.data if item['price']}
    except: return {}

def translate_from_ko(korean_text, target_lang):
    if target_lang == 'ko': return korean_text
    
    if target_lang == 'en': lang_str = "English"
    elif target_lang == 'ja': lang_str = "æ—¥æœ¬èª(Japanese)"
    elif target_lang == 'zh': lang_str = "ç®€ä½“ä¸­æ–‡(Simplified Chinese)"
    
    # ğŸ’¡ 1. ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸ ê°•ë ¥ ì¶”ê°€ (ìê¸°ì†Œê°œ ê¸ˆì§€ í¬í•¨)
    prompt = f"""
    Translate the following Korean financial text into {lang_str}.
    
    [CRITICAL STRICT RULES - PENALTY APPLIED IF VIOLATED]
    1. Target Language ONLY: You MUST write STRICTLY in {lang_str}. 
    2. NO KOREAN ALLOWED: DO NOT use ANY Korean characters (ê°€-í£) in your translated output. If you output even one Korean character, the system will crash.
    3. Maintain a professional Wall Street analyst tone.
    4. Keep ALL HTML tags (<p>, <br>, <b>, etc.) and line breaks exactly as they are.
    5. If there are <JSON_START> and <JSON_END> tags, keep them intact.
    6. DO NOT translate JSON keys.
    7. In JSON, the value for "sentiment" MUST remain exactly as "ê¸ì •", "ë¶€ì •", or "ì¼ë°˜". (This is the ONLY exception where Korean is allowed).
    8. NO INTRODUCTIONS/FILLERS: DO NOT include any self-introductions, greetings, or conversational transitions (e.g., "I am an analyst," "Here is the translation," "Let's look at the article"). START IMMEDIATELY with the translated content from the very first character.
    
    [Korean Text to Translate]
    {korean_text}
    """
    
    # ğŸ’¡ 2. ì¬ì‹œë„(Retry) ë¡œì§ ë° í›„ì²˜ë¦¬ ë°©ì–´ë§‰
    max_retries = 3
    for i in range(max_retries):
        try:
            # Temperature 0.0ìœ¼ë¡œ ê³ ì •í•˜ì—¬ ì°½ì˜ì„±(í™˜ê° ë° ì“¸ë°ì—†ëŠ” ë§) ì–µì œ
            response = standard_model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(temperature=0.0)
            ).text
            
            # ğŸ’¡ 3. íŒŒì´ì¬ í›„ì²˜ë¦¬ ê²€ì¦ (JSON ê°ì„± ê°’ì€ ì œì™¸í•˜ê³  ê²€ì‚¬)
            check_text = response.replace("ê¸ì •", "").replace("ë¶€ì •", "").replace("ì¼ë°˜", "")
            if re.search(r'[ê°€-í£]', check_text):
                print(f"âš ï¸ [Worker] í•œêµ­ì–´ ê°ì§€ë¨ ({target_lang}). ì¬ì‹œë„ {i+1}/{max_retries}")
                time.sleep(1)
                continue # í•œêµ­ì–´ê°€ ë°œê²¬ë˜ë©´ ë°”ë¡œ ë‹¤ì‹œ ëŒë¦¼
                
            return response
        except Exception as e:
            time.sleep(1)
            pass
            
    return korean_text # 3ë²ˆ ë‹¤ ì‹¤íŒ¨í•˜ë©´ ì›ë³¸ ë°˜í™˜


# ==========================================
# [3] AI ë¶„ì„ í•¨ìˆ˜ë“¤ (ë¹„ìš© ìµœì í™” & ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ 100% ë³´ì¡´ & ë§íˆ¬ êµì •)
# ==========================================

# Tab 0: ê³µì‹œ (ì¼ë°˜ ëª¨ë¸)
def run_tab0_analysis(ticker, company_name):
    if not standard_model: return
    
    def_meta = {
        "S-1": "Risk Factors(íŠ¹ì´ ì†Œì†¡/ê·œì œ), Use of Proceeds(ìê¸ˆ ìš©ë„ì˜ ê±´ì „ì„±), MD&A(ì„±ì¥ ë™ì¸)",
        "S-1/A": "Pricing Terms(ìˆ˜ìš”ì˜ˆì¸¡ ë¶„ìœ„ê¸°), Dilution(ì‹ ê·œ íˆ¬ìì í¬ì„ë¥ ), Changes(ì´ì „ ì œì¶œë³¸ê³¼ì˜ ì°¨ì´ì )",
        "F-1": "Foreign Risk(ì§€ì •í•™ì  ë¦¬ìŠ¤í¬), Accounting(GAAP ì°¨ì´), ADS(ì£¼ì‹ ì˜ˆíƒ ì¦ì„œ êµ¬ì¡°)",
        "FWP": "Graphics(ì‹œì¥ ì ìœ ìœ¨ ì‹œê°í™”), Strategy(ë¯¸ë˜ í•µì‹¬ ë¨¹ê±°ë¦¬), Highlights(ê²½ì˜ì§„ ê°•ì¡° ì‚¬í•­)",
        "424B4": "Underwriting(ì£¼ê´€ì‚¬ ë“±ê¸‰), Final Price(ê¸°ê´€ ë°°ì • ë¬¼ëŸ‰), IPO Outcome(ìµœì¢… ê³µëª¨ ê²°ê³¼)"
    }

    # ğŸ’¡ ë§íˆ¬ êµì • ì¶”ê°€
    format_instruction = """
    [ì¶œë ¥ í˜•ì‹ ë° ë²ˆì—­ ê·œì¹™ - ë°˜ë“œì‹œ ì§€í‚¬ ê²ƒ]
    - ê° ë¬¸ë‹¨ì˜ ì‹œì‘ì€ ë°˜ë“œì‹œ í•´ë‹¹ ì–¸ì–´ë¡œ ë²ˆì—­ëœ **[ì†Œì œëª©]**ìœ¼ë¡œ ì‹œì‘í•œ ë’¤, ì¤„ë°”ê¿ˆ ì—†ì´ í•œ ì¹¸ ë„ìš°ê³  ë°”ë¡œ ë‚´ìš©ì„ ì´ì–´ê°€ì„¸ìš”.
    - [ë¶„ëŸ‰ ì¡°ê±´] ì „ì²´ ìš”ì•½ì´ ì•„ë‹™ë‹ˆë‹¤! **ê° ë¬¸ë‹¨(1, 2, 3)ë§ˆë‹¤ ë°˜ë“œì‹œ 4~5ë¬¸ì¥(ì•½ 5ì¤„ ë¶„ëŸ‰)ì”©** ë‚´ìš©ì„ ìƒì„¸í•˜ê³  í’ì„±í•˜ê²Œ ì±„ì›Œ ë„£ìœ¼ì„¸ìš”.
    - ê¸ˆì§€ ì˜ˆì‹œ: **[Heading - í•œêµ­ì–´]** (X), **[Heading]** \n Content (X)
    - [ì–´ì¡° ì¡°ê±´] ëª¨ë“  ë¬¸ì¥ì€ ë°˜ë“œì‹œ '~í•©ë‹ˆë‹¤', '~ì…ë‹ˆë‹¤' í˜•íƒœì˜ ì •ì¤‘í•œ ê²½ì–´ì²´ë¡œ ì‘ì„±í•˜ì„¸ìš”. ('~ì´ë‹¤', '~í•œë‹¤' ì ˆëŒ€ ê¸ˆì§€)
    """

    for topic in ["S-1", "S-1/A", "F-1", "FWP", "424B4"]:
        if topic not in def_meta: continue
        points = def_meta[topic]
        
        prompt_ko = f"""
        Role: Wall Street Senior Analyst.
        Task: Analyze {company_name} ({ticker})'s {topic} filing points: {points}.
        Language: Strictly in ì „ë¬¸ì ì¸ í•œêµ­ì–´(Korean).
        
        [Structure]
        1. First paragraph: Analysis of key investment points in the document.
        2. Second paragraph: Analysis of growth potential and financial implications.
        3. Third paragraph: One key risk factor and its impact.

        {format_instruction}
        """
        try:
            ko_text = standard_model.generate_content(prompt_ko).text
            time.sleep(0.5)
            
            for lang_code in SUPPORTED_LANGS:
                cache_key = f"{company_name}_{topic}_Tab0_v11_{lang_code}"
                final_text = translate_from_ko(ko_text, lang_code)
                batch_upsert("analysis_cache", [{"cache_key": cache_key, "content": final_text, "updated_at": datetime.now().isoformat()}], on_conflict="cache_key")
        except: pass

# Tab 1: ë¹„ì¦ˆë‹ˆìŠ¤ ë° ë‰´ìŠ¤ (ê²€ìƒ‰ ëª¨ë¸ -> ë²ˆì—­)
def run_tab1_analysis(ticker, company_name):
    if not search_model or not standard_model: return
    
    source_text = ""
    try:
        search_prompt = f"""
        Find the detailed business model and 5 recent news articles (last 1 year) for {company_name} ({ticker}).
        Output the news in JSON format inside <NEWS_JSON> tags, and business summary as plain text.
        """
        source_resp = search_model.generate_content(search_prompt)
        source_text = source_resp.text
    except: return 

    json_format = f"""{{ "news": [ {{ "title_en": "Original Title", "translated_title": "í•œêµ­ì–´ ì œëª©", "link": "...", "sentiment": "ê¸ì •/ë¶€ì •/ì¼ë°˜", "date": "YYYY-MM-DD" }} ] }}"""
    
    # ğŸ’¡ ë§íˆ¬ êµì • ì¶”ê°€
    prompt_ko = f"""
    Based on the provided source info below, create a report for {company_name} ({ticker}).
    Source Info: {source_text[:10000]} 

    [Task 1: Business Model]
    - Write 3 paragraphs (Model, Financials, Outlook) in ì „ë¬¸ì ì¸ í•œêµ­ì–´(Korean). ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
    - No headers, just plain text paragraphs.
    - ì£¼ì˜: ëª¨ë“  ë¬¸ì¥ì€ ë°˜ë“œì‹œ '~í•©ë‹ˆë‹¤', '~ì…ë‹ˆë‹¤' í˜•íƒœì˜ ì •ì¤‘í•œ ê²½ì–´ì²´ë¡œ ì‘ì„±í•˜ì„¸ìš”. ('~ì´ë‹¤' ì ˆëŒ€ ê¸ˆì§€)

    [Task 2: News]
    - Extract 5 news from source and format as JSON.
    - Important: Keep 'sentiment' value as "ê¸ì •", "ë¶€ì •", or "ì¼ë°˜" (Korean) regardless of output language.
    
    <JSON_START>
    {json_format}
    <JSON_END>
    """
    try:
        ko_text = standard_model.generate_content(prompt_ko).text
        time.sleep(1)
        
        for lang_code in SUPPORTED_LANGS:
            cache_key = f"{ticker}_Tab1_v2_{lang_code}"
            final_text = translate_from_ko(ko_text, lang_code)
            
            biz_analysis = final_text.split("<JSON_START>")[0].strip()
            biz_analysis = re.sub(r'#.*', '', biz_analysis).strip()
            paragraphs = [p.strip() for p in biz_analysis.split('\n') if len(p.strip()) > 20]
            
            indent_size = "14px" if lang_code == "ko" else "0px"
            html_output = "".join([f'<p style="display:block; text-indent:{indent_size}; margin-bottom:20px; line-height:1.8; text-align:justify; font-size: 15px; color: #333;">{p}</p>' for p in paragraphs])
            
            news_list = []
            if "<JSON_START>" in final_text:
                try: 
                    json_part = final_text.split("<JSON_START>")[1].split("<JSON_END>")[0].strip()
                    news_list = json.loads(json_part).get("news", [])
                except: pass
            
            batch_upsert("analysis_cache", [{"cache_key": cache_key, "content": json.dumps({"html": html_output, "news": news_list}, ensure_ascii=False), "updated_at": datetime.now().isoformat()}], on_conflict="cache_key")
    except: pass

# Tab 3: ì¬ë¬´ ë¶„ì„ (ì¼ë°˜ ëª¨ë¸)
def run_tab3_analysis(ticker, company_name, metrics):
    if not standard_model: return
    
    # ğŸ’¡ ë§íˆ¬ êµì • ì¶”ê°€
    prompt_ko = f"""
    Role: CFA Analyst.
    Task: Write a financial report for {company_name} based on: {metrics}.
    Language: ì „ë¬¸ì ì¸ í•œêµ­ì–´(Korean).
    Format: 4 sections [Valuation], [Operating], [Risk], [Conclusion].
    Length: 10-12 lines total.
    Rule: ëª¨ë“  ë¬¸ì¥ì€ ë°˜ë“œì‹œ '~í•©ë‹ˆë‹¤', '~ì…ë‹ˆë‹¤' í˜•íƒœì˜ ì •ì¤‘í•œ ê²½ì–´ì²´ë¡œ ì‘ì„±í•˜ì„¸ìš”. ('~ì´ë‹¤', '~í•œë‹¤' ì ˆëŒ€ ê¸ˆì§€)
    """
    try:
        ko_text = standard_model.generate_content(prompt_ko).text
        time.sleep(0.5)
        
        for lang_code in SUPPORTED_LANGS:
            cache_key = f"{ticker}_Financial_Report_Tab3_{lang_code}"
            final_text = translate_from_ko(ko_text, lang_code)
            batch_upsert("analysis_cache", [{"cache_key": cache_key, "content": final_text, "updated_at": datetime.now().isoformat()}], on_conflict="cache_key")
    except: pass

# Tab 4: ê¸°ê´€ í‰ê°€ ë¶„ì„ (ê²€ìƒ‰ ëª¨ë¸ -> ë²ˆì—­)
def run_tab4_analysis(ticker, company_name):
    if not search_model or not standard_model: return

    source_text = ""
    try:
        search_prompt = f"Find recent institutional analyst ratings, price targets, and pros/cons reports for {company_name} ({ticker})."
        source_resp = search_model.generate_content(search_prompt)
        source_text = source_resp.text
    except: return

    json_format = '"summary": "3ì¤„ ìš”ì•½ (ë°˜ë“œì‹œ ê²½ì–´ì²´ ì‚¬ìš©)", "pro_con": "**Pros(ì¥ì )**... **Cons(ë‹¨ì )**..."'
    
    # ğŸ’¡ ë§íˆ¬ êµì • ì¶”ê°€
    prompt_ko = f"""
    Using the source info below, create an institutional report summary for {company_name} ({ticker}).
    Source Info: {source_text[:8000]}
    Language: ì „ë¬¸ì ì¸ í•œêµ­ì–´(Korean) (Strictly).
    Rule: ëª¨ë“  ë¬¸ì¥ì€ ë°˜ë“œì‹œ '~í•©ë‹ˆë‹¤', '~ì…ë‹ˆë‹¤' í˜•íƒœì˜ ì •ì¤‘í•œ ê²½ì–´ì²´ë¡œ ì‘ì„±í•˜ì„¸ìš”. ('~ì´ë‹¤' ì ˆëŒ€ ê¸ˆì§€)
    
    <JSON_START>
    {{
        "rating": "Buy/Hold/Sell",
        {json_format},
        "links": [{{"title": "Report Title", "link": "URL"}}]
    }}
    <JSON_END>
    """
    try:
        ko_text = standard_model.generate_content(prompt_ko).text
        time.sleep(1)
        
        for lang_code in SUPPORTED_LANGS:
            cache_key = f"{ticker}_Tab4_{lang_code}"
            final_text = translate_from_ko(ko_text, lang_code)
            
            match = re.search(r'<JSON_START>(.*?)<JSON_END>', final_text, re.DOTALL)
            if match:
                clean_str = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', match.group(1).strip())
                batch_upsert("analysis_cache", [{"cache_key": cache_key, "content": clean_str, "updated_at": datetime.now().isoformat()}], on_conflict="cache_key")
    except: pass

# Tab 2: ê±°ì‹œ ì§€í‘œ (ë‹¨ 1íšŒ ì‹¤í–‰)
def update_macro_data(df):
    if not standard_model: return
    print("ğŸŒ ê±°ì‹œ ì§€í‘œ(Tab 2) 1íšŒ ì—…ë°ì´íŠ¸ ì¤‘...")
    data = {"ipo_return": 15.2, "ipo_volume": len(df), "vix": 14.5, "fear_greed": 60} 
    
    # ğŸ’¡ ë§íˆ¬ êµì • ì¶”ê°€
    prompt_ko = f"Market Data: {data}. Write a 3-line daily market briefing in ì „ë¬¸ì ì¸ í•œêµ­ì–´(Korean). No headers. ëª¨ë“  ë¬¸ì¥ì€ ë°˜ë“œì‹œ '~í•©ë‹ˆë‹¤', '~ì…ë‹ˆë‹¤' í˜•íƒœì˜ ì •ì¤‘í•œ ê²½ì–´ì²´ë¡œ ì‘ì„±í•˜ì„¸ìš”. ('~ì´ë‹¤' ì ˆëŒ€ ê¸ˆì§€)"
    try:
        ko_text = standard_model.generate_content(prompt_ko).text
        ko_text = re.sub(r'^#+.*$', '', ko_text, flags=re.MULTILINE).strip()
        time.sleep(0.5)
        
        for lang_code in SUPPORTED_LANGS:
            cache_key = f"Global_Market_Dashboard_Tab2_{lang_code}"
            final_text = translate_from_ko(ko_text, lang_code)
            batch_upsert("analysis_cache", [{"cache_key": cache_key, "content": final_text, "updated_at": datetime.now().isoformat()}], on_conflict="cache_key")
    except: pass

# ==========================================
# [4] ë©”ì¸ ì‹¤í–‰ ë£¨í”„
# ==========================================
def main():
    print(f"ğŸš€ Worker Start: {datetime.now()}")
    
    df = get_target_stocks()
    if df.empty: 
        print("âš ï¸ ìˆ˜ì§‘ëœ IPO ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    print("\nğŸ“‹ [stock_cache] ëª…ë‹¨ ì—…ë°ì´íŠ¸...")
    now_iso = datetime.now().isoformat()
    stock_list = [{"symbol": str(row['symbol']), "name": str(row['name']) or "Unknown", "last_updated": now_iso} for _, row in df.iterrows()]
    batch_upsert("stock_cache", stock_list, on_conflict="symbol")

    update_macro_data(df)
    
    print("ğŸ”¥ Hot ì¢…ëª© ì„ ë³„ ì¤‘...")
    price_map = get_current_prices() 
    
    today = datetime.now()
    hot_symbols = set()
    
    try:
        df['dt'] = pd.to_datetime(df['date'])
        upcoming = df[(df['dt'] > today) & (df['dt'] <= today + timedelta(days=35))]
        hot_symbols.update(upcoming['symbol'].tolist())
        print(f"   -> ìƒì¥ ì˜ˆì •: {len(upcoming)}ê°œ")
    except: pass
    
    try:
        past_12m = df[(df['dt'] >= today - timedelta(days=365)) & (df['dt'] <= today)].copy()
        def calc_return(row):
            try:
                ipo_p = float(str(row.get('price', '0')).replace('$','').split('-')[0])
                curr_p = price_map.get(row['symbol'], 0.0)
                if ipo_p > 0 and curr_p > 0: return (curr_p - ipo_p) / ipo_p * 100
                return -9999.0
            except: return -9999.0
        past_12m['return'] = past_12m.apply(calc_return, axis=1)
        top_30 = past_12m.sort_values(by='return', ascending=False).head(30)
        hot_symbols.update(top_30['symbol'].tolist())
        print(f"   -> ìˆ˜ìµë¥  ìƒìœ„: 30ê°œ (1ìœ„: {top_30.iloc[0]['symbol']} {top_30.iloc[0]['return']:.1f}%)")
    except Exception as e:
        print(f"   âš ï¸ ìˆ˜ìµë¥  ê³„ì‚° ì—ëŸ¬: {e}")

    print(f"âœ… ìµœì¢… Hot ì¢…ëª©: ì´ {len(hot_symbols)}ê°œ")

    total = len(df)
    print(f"\nğŸ¤– AI ì‹¬ì¸µ ë¶„ì„ ì‹œì‘ (ì´ {total}ê°œ ì¤‘ Hot ì¢…ëª© ìœ„ì£¼ ì‹¤í–‰)...")
    
    for idx, row in df.iterrows():
        symbol = row.get('symbol')
        name = row.get('name')
        
        is_hot = symbol in hot_symbols
        is_full_update = (today.weekday() == 0 or is_hot)
        
        print(f"[{idx+1}/{total}] {symbol} (Hot:{is_hot}) ì²˜ë¦¬ ì¤‘...", flush=True)
        
        try:
            if is_hot:
                run_tab1_analysis(symbol, name)
                if is_full_update:
                    run_tab4_analysis(symbol, name)
            
            if is_full_update:
                run_tab0_analysis(symbol, name)
                try:
                    tk = yf.Ticker(symbol)
                    run_tab3_analysis(symbol, name, {"pe": tk.info.get('forwardPE', 0)})
                except: pass
            
            time.sleep(0.5) 
            
        except Exception as e:
            print(f"âš ï¸ {symbol} ê±´ë„ˆëœ€: {e}")
            continue
            
    print(f"\nğŸ ëª¨ë“  ì‘ì—… ì¢…ë£Œ: {datetime.now()}")

if __name__ == "__main__":
    main()
