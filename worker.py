import os
import time
import json
import re
import requests
import pandas as pd
import numpy as np
import yfinance as yf
import logging
from datetime import datetime, timedelta

from supabase import create_client
import google.generativeai as genai

# ==========================================
# [1] í™˜ê²½ ì„¤ì •
# ==========================================
raw_url = os.environ.get("SUPABASE_URL", "")
if "/rest/v1" in raw_url:
    SUPABASE_URL = raw_url.split("/rest/v1")[0].rstrip('/')
else:
    SUPABASE_URL = raw_url.rstrip('/')

SUPABASE_KEY = os.environ.get("SUPABASE_KEY", "")
GENAI_API_KEY = os.environ.get("GENAI_API_KEY", "")
FINNHUB_API_KEY = os.environ.get("FINNHUB_API_KEY", "")

logging.getLogger('yfinance').setLevel(logging.CRITICAL)

if not (SUPABASE_URL and SUPABASE_KEY):
    print("âŒ í™˜ê²½ë³€ìˆ˜ ëˆ„ë½ (SUPABASE_URL ë˜ëŠ” KEY)")
    exit()

try:
    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
except Exception as e:
    print(f"âŒ Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    exit()

model = None 
if GENAI_API_KEY:
    genai.configure(api_key=GENAI_API_KEY)
    try:
        model = genai.GenerativeModel('gemini-2.0-flash', tools=[{'google_search_retrieval': {}}])
        print("âœ… AI ëª¨ë¸ ë¡œë“œ ì„±ê³µ (Search Tool í™œì„±í™”)")
    except:
        model = genai.GenerativeModel('gemini-2.0-flash')
        print("âš ï¸ AI ëª¨ë¸ ê¸°ë³¸ ë¡œë“œ (Search Tool ì œì™¸)")

SUPPORTED_LANGS = {
    'ko': 'ì „ë¬¸ì ì¸ í•œêµ­ì–´(Korean)',
    'en': 'Professional English',
    'ja': 'å°‚é–€çš„ãªæ—¥æœ¬èª(Japanese)'
}

# ==========================================
# [2] í—¬í¼ í•¨ìˆ˜
# ==========================================
def sanitize_value(v):
    if v is None or pd.isna(v): return None
    if isinstance(v, (np.floating, float)):
        return float(v) if not (np.isinf(v) or np.isnan(v)) else 0.0
    if isinstance(v, (np.integer, int)): return int(v)
    if isinstance(v, (np.bool_, bool)): return bool(v)
    return str(v).strip().replace('\x00', '')

def batch_upsert(table_name, data_list, on_conflict="ticker"):
    if not data_list: return
    endpoint = f"{SUPABASE_URL}/rest/v1/{table_name}?on_conflict={on_conflict}"
    headers = {
        "apikey": SUPABASE_KEY,
        "Authorization": f"Bearer {SUPABASE_KEY}",
        "Content-Type": "application/json",
        "Prefer": "return=minimal,resolution=merge-duplicates" 
    }
    clean_batch = []
    for item in data_list:
        payload = {k: sanitize_value(v) for k, v in item.items()}
        if payload.get(on_conflict):
            clean_batch.append(payload)

    if not clean_batch: return

    try:
        resp = requests.post(endpoint, json=clean_batch, headers=headers)
        if resp.status_code in [200, 201, 204]:
            print(f"âœ… [{table_name}] {len(clean_batch)}ê°œ ì €ì¥ ì„±ê³µ")
        else:
            print(f"âŒ [{table_name}] ì €ì¥ ì‹¤íŒ¨ ({resp.status_code})")
    except Exception as e:
        print(f"âŒ [{table_name}] í†µì‹  ì—ëŸ¬: {e}")

def get_target_stocks():
    if not FINNHUB_API_KEY: return pd.DataFrame()
    now = datetime.now()
    ranges = [
        (now - timedelta(days=200), now + timedelta(days=35)), 
        (now - timedelta(days=380), now - timedelta(days=170)), 
        (now - timedelta(days=560), now - timedelta(days=350))
    ]
    all_data = []
    for start_dt, end_dt in ranges:
        url = f"https://finnhub.io/api/v1/calendar/ipo?from={start_dt.strftime('%Y-%m-%d')}&to={end_dt.strftime('%Y-%m-%d')}&token={FINNHUB_API_KEY}"
        try:
            res = requests.get(url, timeout=10).json()
            if res.get('ipoCalendar'): all_data.extend(res['ipoCalendar'])
        except: continue
        
    if not all_data: return pd.DataFrame()
    df = pd.DataFrame(all_data).dropna(subset=['symbol'])
    df['symbol'] = df['symbol'].astype(str).str.strip()
    return df.drop_duplicates(subset=['symbol'])


# ==========================================
# [3] AI ë¶„ì„ í•¨ìˆ˜ë“¤ (app.pyì™€ ì™„ë²½ ë™ê¸°í™”)
# ==========================================

def run_tab0_analysis(ticker, company_name):
    """Tab 0: ê³µì‹œ 5ì¢… ë¶„ì„ (í¬ë§·íŒ… ê°•ì œ ì˜ˆì‹œ ì ìš© + v10 ìºì‹œí‚¤)"""
    if not model: return
    
    def_meta = {
        "S-1": {
            "points": "Risk Factors(íŠ¹ì´ ì†Œì†¡/ê·œì œ), Use of Proceeds(ìê¸ˆ ìš©ë„ì˜ ê±´ì „ì„±), MD&A(ì„±ì¥ ë™ì¸)",
            "structure": """
            [ë¬¸ë‹¨ êµ¬ì„± ì§€ì¹¨]
            1. ì²« ë²ˆì§¸ ë¬¸ë‹¨: í•´ë‹¹ ë¬¸ì„œì—ì„œ ë°œê²¬ëœ ê°€ì¥ ì¤‘ìš”í•œ íˆ¬ì í¬ì¸íŠ¸ ë¶„ì„
            2. ë‘ ë²ˆì§¸ ë¬¸ë‹¨: ì‹¤ì§ˆì  ì„±ì¥ ê°€ëŠ¥ì„±ê³¼ ì¬ë¬´ì  ì˜ë¯¸ ë¶„ì„
            3. ì„¸ ë²ˆì§¸ ë¬¸ë‹¨: í•µì‹¬ ë¦¬ìŠ¤í¬ 1ê°€ì§€ì™€ ê·¸ íŒŒê¸‰ íš¨ê³¼ ë° ëŒ€ì‘ì±…
            """
        },
        "S-1/A": {
            "points": "Pricing Terms(ìˆ˜ìš”ì˜ˆì¸¡ ë¶„ìœ„ê¸°), Dilution(ì‹ ê·œ íˆ¬ìì í¬ì„ë¥ ), Changes(ì´ì „ ì œì¶œë³¸ê³¼ì˜ ì°¨ì´ì )",
            "structure": """
            [ë¬¸ë‹¨ êµ¬ì„± ì§€ì¹¨]
            1. ì²« ë²ˆì§¸ ë¬¸ë‹¨: ì´ì „ S-1 ëŒ€ë¹„ ë³€ê²½ëœ í•µì‹¬ ì‚¬í•­ ë¶„ì„
            2. ë‘ ë²ˆì§¸ ë¬¸ë‹¨: ì œì‹œëœ ê³µëª¨ê°€ ë²”ìœ„ì˜ ì ì •ì„± ë° ìˆ˜ìš”ì˜ˆì¸¡ ë¶„ìœ„ê¸° ë¶„ì„
            3. ì„¸ ë²ˆì§¸ ë¬¸ë‹¨: ê¸°ì¡´ ì£¼ì£¼ ê°€ì¹˜ í¬ì„ ì •ë„ì™€ íˆ¬ì ë§¤ë ¥ë„ ë¶„ì„
            """
        },
        "F-1": {
            "points": "Foreign Risk(ì§€ì •í•™ì  ë¦¬ìŠ¤í¬), Accounting(GAAP ì°¨ì´), ADS(ì£¼ì‹ ì˜ˆíƒ ì¦ì„œ êµ¬ì¡°)",
            "structure": """
            [ë¬¸ë‹¨ êµ¬ì„± ì§€ì¹¨]
            1. ì²« ë²ˆì§¸ ë¬¸ë‹¨: ê¸°ì—…ì´ ê¸€ë¡œë²Œ ì‹œì¥ì—ì„œ ê°€ì§„ ë…ë³´ì ì¸ ê²½ìŸ ìš°ìœ„
            2. ë‘ ë²ˆì§¸ ë¬¸ë‹¨: í™˜ìœ¨, ì •ì¹˜, íšŒê³„ ë“± í•´ì™¸ ê¸°ì—… íŠ¹ìœ ì˜ ë¦¬ìŠ¤í¬ ë¶„ì„
            3. ì„¸ ë²ˆì§¸ ë¬¸ë‹¨: ë¯¸êµ­ ì˜ˆíƒ ì¦ì„œ(ADS) êµ¬ì¡°ê°€ ì£¼ì£¼ ê¶Œë¦¬ì— ë¯¸ì¹˜ëŠ” ì˜í–¥
            """
        },
        "FWP": {
            "points": "Graphics(ì‹œì¥ ì ìœ ìœ¨ ì‹œê°í™”), Strategy(ë¯¸ë˜ í•µì‹¬ ë¨¹ê±°ë¦¬), Highlights(ê²½ì˜ì§„ ê°•ì¡° ì‚¬í•­)",
            "structure": """
            [ë¬¸ë‹¨ êµ¬ì„± ì§€ì¹¨]
            1. ì²« ë²ˆì§¸ ë¬¸ë‹¨: ê²½ì˜ì§„ì´ ë¡œë“œì‡¼ì—ì„œ ê°•ì¡°í•˜ëŠ” ë¯¸ë˜ ì„±ì¥ ë¹„ì „
            2. ë‘ ë²ˆì§¸ ë¬¸ë‹¨: ê²½ìŸì‚¬ ëŒ€ë¹„ ë¶€ê°ì‹œí‚¤ëŠ” ê¸°ìˆ ì /ì‚¬ì—…ì  ì°¨ë³„í™” í¬ì¸íŠ¸
            3. ì„¸ ë²ˆì§¸ ë¬¸ë‹¨: ìë£Œ í†¤ì•¤ë§¤ë„ˆë¡œ ìœ ì¶”í•  ìˆ˜ ìˆëŠ” ì‹œì¥ ê³µëµ ì˜ì§€
            """
        },
        "424B4": {
            "points": "Underwriting(ì£¼ê´€ì‚¬ ë“±ê¸‰), Final Price(ê¸°ê´€ ë°°ì • ë¬¼ëŸ‰), IPO Outcome(ìµœì¢… ê³µëª¨ ê²°ê³¼)",
            "structure": """
            [ë¬¸ë‹¨ êµ¬ì„± ì§€ì¹¨]
            1. ì²« ë²ˆì§¸ ë¬¸ë‹¨: í™•ì • ê³µëª¨ê°€ì˜ ìœ„ì¹˜ì™€ ì‹œì¥ ìˆ˜ìš” í•´ì„
            2. ë‘ ë²ˆì§¸ ë¬¸ë‹¨: í™•ì •ëœ ì¡°ë‹¬ ìê¸ˆì˜ íˆ¬ì… ìš°ì„ ìˆœìœ„ ì ê²€
            3. ì„¸ ë²ˆì§¸ ë¬¸ë‹¨: ì£¼ê´€ì‚¬ë‹¨ ë° ë°°ì • ë¬¼ëŸ‰ ë°”íƒ• ìƒì¥ ì´ˆê¸° ìœ í†µë¬¼ëŸ‰ ì˜ˆì¸¡
            """
        }
    }

    format_instruction = """
                [ì¶œë ¥ í˜•ì‹ ë° ë²ˆì—­ ê·œì¹™ - ë°˜ë“œì‹œ ì§€í‚¬ ê²ƒ]
                - ê° ë¬¸ë‹¨ì˜ ì‹œì‘ì€ ë°˜ë“œì‹œ í•´ë‹¹ ì–¸ì–´ë¡œ ë²ˆì—­ëœ **[ì†Œì œëª©]**ìœ¼ë¡œ ì‹œì‘í•œ ë’¤, ì¤„ë°”ê¿ˆ ì—†ì´ í•œ ì¹¸ ë„ìš°ê³  ë°”ë¡œ ë‚´ìš©ì„ ì´ì–´ê°€ì„¸ìš”.
                - [ë¶„ëŸ‰ ì¡°ê±´] ì „ì²´ ìš”ì•½ì´ ì•„ë‹™ë‹ˆë‹¤! **ê° ë¬¸ë‹¨(1, 2, 3)ë§ˆë‹¤ ë°˜ë“œì‹œ 4~5ë¬¸ì¥(ì•½ 5ì¤„ ë¶„ëŸ‰)ì”©** ë‚´ìš©ì„ ìƒì„¸í•˜ê³  í’ì„±í•˜ê²Œ ì±„ì›Œ ë„£ìœ¼ì„¸ìš”.
                - ì˜¬ë°”ë¥¸ ì˜ˆì‹œ(ì˜ì–´): **[Investment Point]** The company's main advantage is...
                - ì˜¬ë°”ë¥¸ ì˜ˆì‹œ(ì¼ë³¸ì–´): **[æŠ•è³‡ãƒã‚¤ãƒ³ãƒˆ]** åŒç¤¾ã®æœ€å¤§ã®å¼·ã¿ã¯...
                - ê¸ˆì§€ ì˜ˆì‹œ(í•œêµ­ì–´ ë³‘ê¸° ì ˆëŒ€ ê¸ˆì§€): **[Investment Point - íˆ¬ìí¬ì¸íŠ¸]** (X)
                - ê¸ˆì§€ ì˜ˆì‹œ(ì†Œì œëª© ë’¤ ì¤„ë°”ê¿ˆ ì ˆëŒ€ ê¸ˆì§€): **[æŠ•è³‡ãƒã‚¤ãƒ³ãƒˆ]** \n åŒç¤¾ã¯... (X)
                """

    # ğŸ’¡ ì›Œì»¤ì—ì„œë„ 5ê°€ì§€ ì£¼ìš” ì„œë¥˜ë¥¼ ëª¨ë‘ ìºì‹±í•˜ë„ë¡ í™•ì¥
    for topic in ["S-1", "S-1/A", "F-1", "FWP", "424B4"]:
        curr_meta = def_meta[topic]
        
        for lang_code, target_lang in SUPPORTED_LANGS.items():
            # ğŸš¨ [ìºì‹œí‚¤ ë™ê¸°í™”] v10
            cache_key = f"{company_name}_{topic}_Tab0_v11_{lang_code}"
            
            if lang_code == 'en':
                labels = ["Analysis Target", "Instructions", "Structure & Format", "Writing Style Guide"]
                role_desc = "You are a professional senior analyst from Wall Street."
                no_intro_prompt = 'CRITICAL: NEVER introduce yourself. DO NOT include Korean translations in headings. START IMMEDIATELY with the first English **[Heading]**.'
                lang_directive = "The guide below is in Korean for reference, but you MUST translate all headings and content into English."
            elif lang_code == 'ja':
                labels = ["åˆ†æå¯¾è±¡", "æŒ‡é‡", "å†…å®¹æ§‹æˆãŠã‚ˆã³å½¢å¼", "æ–‡ä½“ã‚¬ã‚¤ãƒ‰"]
                role_desc = "ã‚ãªãŸã¯ã‚¦ã‚©ãƒ¼ãƒ«è¡—å‡ºèº«ã®å°‚é–€åˆ†æå®¶ã§ã™ã€‚"
                no_intro_prompt = 'ã€é‡è¦ã€‘è‡ªå·±ç´¹ä»‹ã¯çµ¶å¯¾ã«ç¦æ­¢ã§ã™ã€‚è¦‹å‡ºã—ã«éŸ“å›½èªã‚’ä½µè¨˜ã—ãªã„ã§ãã ã•ã„ã€‚1æ–‡å­—ç›®ã‹ã‚‰ã„ããªã‚Šæ—¥æœ¬èªã®**[è¦‹å‡ºã—]**ã§æœ¬è«–ã‹ã‚‰å§‹ã‚ã¦ãã ã•ã„ã€‚'
                lang_directive = "æ§‹æˆ ê°€ì´ë“œëŠ” ì°¸ê³ ìš©ìœ¼ë¡œ í•œêµ­ì–´ë¡œæä¾›ë˜ë‚˜,ã™ã¹ã¦ã®è¦‹å‡ºã—ã¨å†…å®¹ã¯å¿…ãšæ—¥æœ¬èª(Japanese)ã®ã¿ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚"
            else:
                labels = ["ë¶„ì„ ëŒ€ìƒ", "ì§€ì¹¨", "ë‚´ìš© êµ¬ì„± ë° í˜•ì‹ - ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ì„ ë”°ë¥¼ ê²ƒ", "ë¬¸ì²´ ê°€ì´ë“œ"]
                role_desc = "ë‹¹ì‹ ì€ ì›”ê°€ ì¶œì‹ ì˜ ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤."
                no_intro_prompt = 'ìê¸°ì†Œê°œë‚˜ ì¸ì‚¬ë§, ì„œë¡ ì€ ì ˆëŒ€ í•˜ì§€ ë§ˆì„¸ìš”. 1ê¸€ìë¶€í„° ë°”ë¡œ ë³¸ë¡ (**[ì†Œì œëª©]**)ìœ¼ë¡œ ì‹œì‘í•˜ì„¸ìš”.'
                lang_directive = ""

            prompt = f"""
            {labels[0]}: {company_name} - {topic}
            {labels[1]} (Checkpoints): {curr_meta['points']}
            
            [{labels[1]}]
            {role_desc}
            {no_intro_prompt}
            {lang_directive}
            
            [{labels[2]}]
            {curr_meta['structure']}
            {format_instruction}

            [{labels[3]}]
            - ë°˜ë“œì‹œ '{target_lang}'ë¡œë§Œ ì‘ì„±í•˜ì„¸ìš”. (ì ˆëŒ€ ë‹¤ë¥¸ ì–¸ì–´ë¥¼ ì„ì§€ ë§ˆì„¸ìš”)
            - ë¬¸ì¥ ëì´ ëŠê¸°ì§€ ì•Šë„ë¡ ë§¤ë„ëŸ½ê²Œ ì—°ê²°í•˜ì„¸ìš”.
            """
            try:
                response = model.generate_content(prompt)
                batch_upsert("analysis_cache", [{"cache_key": cache_key, "content": response.text, "updated_at": datetime.now().isoformat()}], on_conflict="cache_key")
                time.sleep(1) # API ì°¨ë‹¨ ë°©ì§€ íœ´ì‹
            except: pass

def run_tab1_analysis(ticker, company_name):
    """Tab 1: ë¹„ì¦ˆë‹ˆìŠ¤ ìš”ì•½ ë° ë‰´ìŠ¤ (v2 ìºì‹œí‚¤ ë™ê¸°í™”)"""
    if not model: return False
    now = datetime.now()
    current_date = now.strftime("%Y-%m-%d")
    
    for lang_code, _ in SUPPORTED_LANGS.items():
        cache_key = f"{ticker}_Tab1_v2_{lang_code}"
        
        # ğŸ’¡ [í•µì‹¬] ì‹œìŠ¤í…œ ì§€ì‹œì–´ì™€ JSON êµ¬ì¡°ë¥¼ ì–¸ì–´ë³„ë¡œ ì™„ì „íˆ ë¶„ë¦¬
        if lang_code == 'ja':
            sys_prompt = "ã‚ãªãŸã¯æœ€é«˜ãƒ¬ãƒ™ãƒ«ã®è¨¼åˆ¸ä¼šç¤¾ãƒªã‚µãƒ¼ãƒã‚»ãƒ³ã‚¿ãƒ¼ã®ã‚·ãƒ‹ã‚¢ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚ã™ã¹ã¦ã®å›ç­”ã¯å¿…ãšæ—¥æœ¬èªã§ä½œæˆã—ã¦ãã ã•ã„ã€‚éŸ“å›½èªã¯çµ¶å¯¾ã«ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚"
            json_format = f"""{{ "news": [ {{ "title_en": "Original English Title", "translated_title": "æ—¥æœ¬èªã«ç¿»è¨³ã•ã‚ŒãŸã‚¿ã‚¤ãƒˆãƒ«", "link": "...", "sentiment": "ê¸ì •/ë¶€ì •/ì¼ë°˜", "date": "YYYY-MM-DD" }} ] }}"""
        elif lang_code == 'en':
            sys_prompt = "You are a senior analyst at a top-tier brokerage research center. You MUST write strictly in English. Do not use any Korean words."
            json_format = f"""{{ "news": [ {{ "title_en": "Original English Title", "translated_title": "Same as English Title", "link": "...", "sentiment": "ê¸ì •/ë¶€ì •/ì¼ë°˜", "date": "YYYY-MM-DD" }} ] }}"""
        else:
            sys_prompt = "ë‹¹ì‹ ì€ ìµœê³  ìˆ˜ì¤€ì˜ ì¦ê¶Œì‚¬ ë¦¬ì„œì¹˜ ì„¼í„°ì˜ ì‹œë‹ˆì–´ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”."
            json_format = f"""{{ "news": [ {{ "title_en": "Original English Title", "translated_title": "í•œêµ­ì–´ë¡œ ë²ˆì—­ëœ ì œëª©", "link": "...", "sentiment": "ê¸ì •/ë¶€ì •/ì¼ë°˜", "date": "YYYY-MM-DD" }} ] }}"""

        prompt = f"""
        {sys_prompt}
        ë¶„ì„ ëŒ€ìƒ: {company_name} ({ticker}) ì˜¤ëŠ˜ ë‚ ì§œ: {current_date}

        [ì‘ì—… 1: ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ ì‹¬ì¸µ ë¶„ì„]
        - ë°˜ë“œì‹œ 3ê°œì˜ ë¬¸ë‹¨(ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸, ì¬ë¬´ í˜„í™©, í–¥í›„ ì „ë§)ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì‘ì„±í•˜ì„¸ìš”.
        - ì œëª©, ì†Œì œëª©, íŠ¹ìˆ˜ê¸°í˜¸, ë¶ˆë ›í¬ì¸íŠ¸(-) ì—†ì´ ë°”ë¡œ ë³¸ë¡ ë¶€í„° ì¤„ê¸€ë¡œ ì‹œì‘í•˜ì„¸ìš”.

        [ì‘ì—… 2: ìµœì‹  ë‰´ìŠ¤ ìˆ˜ì§‘]
        - êµ¬ê¸€ ê²€ìƒ‰ì„ í†µí•´ ìµœê·¼ 1ë…„ ì´ë‚´ì˜ ì˜ë¬¸ ë‰´ìŠ¤ 5ê°œë¥¼ ì°¾ìœ¼ì„¸ìš”.
        - [ì¤‘ìš”] sentiment ê°’ì€ íŒŒì´ì¬ ë¡œì§ ì²˜ë¦¬ë¥¼ ìœ„í•´ ë°˜ë“œì‹œ "ê¸ì •", "ë¶€ì •", "ì¼ë°˜" ì¤‘ í•˜ë‚˜ë¡œ(í•œêµ­ì–´ë¡œ) ìœ ì§€í•˜ì„¸ìš”.
        
        <JSON_START>
        {json_format}
        <JSON_END>
        """
        try:
            response = model.generate_content(prompt)
            full_text = response.text
            
            biz_analysis = full_text.split("<JSON_START>")[0].strip()
            biz_analysis = re.sub(r'#.*', '', biz_analysis).strip()
            paragraphs = [p.strip() for p in biz_analysis.split('\n') if len(p.strip()) > 20]
            
            indent_size = "14px" if lang_code == "ko" else "0px"
            html_output = "".join([f'<p style="display:block; text-indent:{indent_size}; margin-bottom:20px; line-height:1.8; text-align:justify; font-size: 15px; color: #333;">{p}</p>' for p in paragraphs])
            
            news_list = []
            if "<JSON_START>" in full_text:
                try: 
                    json_part = full_text.split("<JSON_START>")[1].split("<JSON_END>")[0].strip()
                    news_list = json.loads(json_part).get("news", [])
                except: pass
                
            batch_upsert("analysis_cache", [{"cache_key": cache_key, "content": json.dumps({"html": html_output, "news": news_list}, ensure_ascii=False), "updated_at": datetime.now().isoformat()}], on_conflict="cache_key")
            time.sleep(1.5)
        except: pass


def run_tab4_analysis(ticker, company_name):
    """Tab 4: ì›”ê°€ ê¸°ê´€ ë¶„ì„ (ê°•ë ¥ íŒŒì‹± + ë””í…Œì¼ í”„ë¡¬í”„íŠ¸ ë³´ì¡´íŒ - Worker ìš©)"""
    if not model: return False
    
    # worker.pyëŠ” ì§€ì›í•˜ëŠ” ëª¨ë“  ì–¸ì–´(SUPPORTED_LANGS)ë¥¼ ìˆœíšŒí•˜ë©° ëª¨ë‘ ìºì‹±í•©ë‹ˆë‹¤.
    for lang_code, _ in SUPPORTED_LANGS.items():
        cache_key = f"{ticker}_Tab4_{lang_code}"
        
        LANG_MAP = {
            'ko': 'í•œêµ­ì–´ (Korean)',
            'en': 'ì˜ì–´ (English)',
            'ja': 'ì¼ë³¸ì–´ (Japanese)'
        }
        target_lang = LANG_MAP.get(lang_code, 'í•œêµ­ì–´ (Korean)')

        # ğŸ’¡ [í•µì‹¬] ì–¸ì–´ í˜¼ìš© ë°©ì§€ í”„ë¡¬í”„íŠ¸ (app.pyì™€ ì™„ë²½íˆ ë™ì¼í•œ êµ¬ì¡°)
        if lang_code == 'ja':
            lang_instruction = "å¿…ãšæ—¥æœ¬èª(Japanese)ã®ã¿ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚ã™ã¹ã¦ã®æ–‡ç« ã¯æ—¥æœ¬èªã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚éŸ“å›½èªã¯çµ¶å¯¾ã«æ··ãœãªã„ã§ãã ã•ã„ã€‚"
            json_summary = "æ—¥æœ¬èªã«ã‚ˆã‚‹å°‚é–€çš„ãª3è¡Œè¦ç´„"
            json_pro_con = "**Pros(é•·æ‰€)**:\\n- å†…å®¹\\n\\n**Cons(çŸ­æ‰€)**:\\n- å†…å®¹ (å¿…ãšæ—¥æœ¬èªã§)"
        elif lang_code == 'en':
            lang_instruction = "Respond strictly in English. Do not mix Korean or any other languages. All sentences must be in English."
            json_summary = "Professional 3-line summary in English"
            json_pro_con = "**Pros**:\\n- Details\\n\\n**Cons**:\\n- Details (All in English)"
        else:
            lang_instruction = "ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”."
            json_summary = "í•œêµ­ì–´ ì „ë¬¸ 3ì¤„ ìš”ì•½"
            json_pro_con = "**Pros(ì¥ì )**:\\n- ë‚´ìš©\\n\\n**Cons(ë‹¨ì )**:\\n- ë‚´ìš© (í•œêµ­ì–´)"

        prompt = f"""
        ë‹¹ì‹ ì€ ì›”ê°€ ì¶œì‹ ì˜ IPO ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤. 
        êµ¬ê¸€ ê²€ìƒ‰ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ {company_name} ({ticker})ì— ëŒ€í•œ ìµœì‹  ê¸°ê´€ ë¦¬í¬íŠ¸(Seeking Alpha, Renaissance Capital, Morningstar ë“±)ë¥¼ ì°¾ì•„ ì‹¬ì¸µ ë¶„ì„í•˜ì„¸ìš”.

        [ì‘ì„± ì§€ì¹¨]
        1. **ì–¸ì–´**: ë°˜ë“œì‹œ '{target_lang}'ë¡œ ë‹µë³€í•˜ì„¸ìš”. {lang_instruction}
        2. **ë¶„ì„ ê¹Šì´**: ë‹¨ìˆœ ì‚¬ì‹¤ ë‚˜ì—´ì´ ì•„ë‹Œ, êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë‚˜ ê·¼ê±°ë¥¼ ë“¤ì–´ ì „ë¬¸ì ìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”.
        3. **Pros & Cons**: ê¸ì •ì  ìš”ì†Œ(Pros) 2ê°€ì§€ì™€ ë¶€ì •ì /ë¦¬ìŠ¤í¬ ìš”ì†Œ(Cons) 2ê°€ì§€ë¥¼ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ ìƒì„¸í•˜ê²Œ ì„œìˆ í•˜ì„¸ìš”.
        4. **Rating**: ì „ë°˜ì ì¸ ì›”ê°€ ë¶„ìœ„ê¸°ë¥¼ ì¢…í•©í•˜ì—¬ ë°˜ë“œì‹œ (Strong Buy/Buy/Hold/Sell) ì¤‘ í•˜ë‚˜ë¡œ ì„ íƒí•˜ì„¸ìš”. (ì´ ê°’ì€ ì˜ì–´ë¡œ ìœ ì§€)
        5. **Summary**: ì „ë¬¸ì ì¸ í†¤ìœ¼ë¡œ 5ì¤„ ì´ë‚´ë¡œ í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
        6. **ë§í¬ ìœ„ì¹˜ êµ¬ë¶„**: 
           - 'summary'ì™€ 'pro_con' ë³¸ë¬¸ ì•ˆì—ëŠ” ì ˆëŒ€ URL(http...)ì„ ë„£ì§€ ë§ˆì„¸ìš”. 
           - ëŒ€ì‹ , ì°¸ì¡°í•œ ë¦¬í¬íŠ¸ì˜ ì‹¤ì œ URLì€ ë°˜ë“œì‹œ í•˜ë‹¨ì˜ **"links" ë¦¬ìŠ¤íŠ¸ ì•ˆì—ë§Œ** ì •í™•íˆ ê¸°ì…í•˜ì„¸ìš”. AIì˜ ê±°ì ˆ ë¬¸êµ¬(linksë¥¼ ì œê³µí•  ìˆ˜ ì—†ë‹¤ ë“±)ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ë„£ì§€ ë§ˆì„¸ìš”.
           
        <JSON_START>
        {{
            "rating": "Buy/Hold/Sell ì¤‘ í•˜ë‚˜",
            "summary": "{json_summary}",
            "pro_con": "{json_pro_con}",
            "links": [
                {{"title": "ê²€ìƒ‰ëœ ë¦¬í¬íŠ¸ ì œëª©", "link": "URL"}}
            ]
        }}
        <JSON_END>
        """
        
        try:
            response = model.generate_content(prompt)
            full_text = response.text
            
            json_match = re.search(r'<JSON_START>(.*?)<JSON_END>', full_text, re.DOTALL)
            json_str = json_match.group(1).strip() if json_match else ""

            if not json_str:
                json_match = re.search(r'\{.*\}', full_text, re.DOTALL)
                json_str = json_match.group(0).strip() if json_match else ""

            if json_str:
                clean_str = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', json_str)
                # worker.pyëŠ” batch_upsertë¥¼ ì‚¬ìš©í•˜ì—¬ DBì— ë°€ì–´ ë„£ìŠµë‹ˆë‹¤.
                batch_upsert("analysis_cache", [{"cache_key": cache_key, "content": clean_str, "updated_at": datetime.now().isoformat()}], on_conflict="cache_key")
            
            # API ì œí•œ(Rate Limit) ë°©ì§€ë¥¼ ìœ„í•œ íœ´ì‹
            time.sleep(1)
        except Exception as e:
            # worker.pyëŠ” ì—ëŸ¬ê°€ ë‚˜ë„ í„°ì§€ì§€ ì•Šê³  ë‹¤ìŒ ì¢…ëª©ìœ¼ë¡œ ë„˜ì–´ê°€ë„ë¡ ì¡°ìš©íˆ ë„˜ê¹ë‹ˆë‹¤.
            pass

def run_tab3_analysis(ticker, company_name, metrics):
    """Tab 3: ì¬ë¬´ ë°ì´í„° ë¶„ì„ ë¦¬í¬íŠ¸"""
    if not model: return False
    for lang_code, target_lang in SUPPORTED_LANGS.items():
        cache_key = f"{ticker}_Financial_Report_Tab3_{lang_code}"
        
        prompt = f"""
        ë‹¹ì‹ ì€ CFA ìê²©ì„ ë³´ìœ í•œ ìˆ˜ì„ ì£¼ì‹ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
        ì•„ë˜ ì¬ë¬´ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ {company_name} ({ticker})ì— ëŒ€í•œ íˆ¬ì ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
        ì¬ë¬´ ë°ì´í„°: {metrics}

        [ì‘ì„± ê°€ì´ë“œ]
        1. ì–¸ì–´: ë°˜ë“œì‹œ '{target_lang}'ë¡œ ì‘ì„±í•˜ì„¸ìš”.
        2. í˜•ì‹: ì•„ë˜ 4ê°€ì§€ ì†Œì œëª©ì„ ë°˜ë“œì‹œ ì‚¬ìš©í•˜ì—¬ ë‹¨ë½ì„ êµ¬ë¶„í•˜ì„¸ìš”. (ì†Œì œëª© ìì²´ë„ {target_lang}ì— ë§ê²Œ ë²ˆì—­í•˜ì„¸ìš”)
           **[Valuation & Market Position]**
           **[Operating Performance]**
           **[Risk & Solvency]**
           **[Analyst Conclusion]**
        3. ë‚´ìš©: ìˆ˜ì¹˜ë¥¼ ë‹¨ìˆœ ë‚˜ì—´í•˜ì§€ ë§ê³ , ìˆ˜ì¹˜ê°€ ê°–ëŠ” í•¨ì˜(í”„ë¦¬ë¯¸ì—„, íš¨ìœ¨ì„±, ë¦¬ìŠ¤í¬ ë“±)ë¥¼ í•´ì„í•˜ì„¸ìš”. ë¶„ëŸ‰ì€ 10~12ì¤„ ë‚´ì™¸ë¡œ í•µì‹¬ë§Œ ìš”ì•½í•˜ì„¸ìš”.
        """
        try:
            response = model.generate_content(prompt)
            batch_upsert("analysis_cache", [{"cache_key": cache_key, "content": response.text, "updated_at": datetime.now().isoformat()}], on_conflict="cache_key")
            time.sleep(1)
        except: pass

def run_tab1_analysis(ticker, company_name):
    """Tab 1: ë¹„ì¦ˆë‹ˆìŠ¤ ìš”ì•½ ë° ë‰´ìŠ¤ (v2 ìºì‹œí‚¤ ë™ê¸°í™”) - ë””í…Œì¼ í”„ë¡¬í”„íŠ¸ ë³´ì¡´íŒ"""
    if not model: return False
    now = datetime.now()
    current_date = now.strftime("%Y-%m-%d")
    
    for lang_code, _ in SUPPORTED_LANGS.items():
        cache_key = f"{ticker}_Tab1_v2_{lang_code}"
        
        # ğŸ’¡ [í•µì‹¬] ì–¸ì–´ë³„ ì‹œìŠ¤í…œ ì§€ì‹œì–´ì™€ ì‚¬ìš©ì ì§€ì¹¨(Label) ë¶„ë¦¬
        if lang_code == 'ja':
            sys_prompt = "ã‚ãªãŸã¯æœ€é«˜ãƒ¬ãƒ™ãƒ«ã®è¨¼åˆ¸ä¼šç¤¾ãƒªã‚µãƒ¼ãƒã‚»ãƒ³ã‚¿ãƒ¼ã®ã‚·ãƒ‹ã‚¢ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚ã™ã¹ã¦ã®å›ç­”ã¯å¿…ãšæ—¥æœ¬èªã§ä½œæˆã—ã¦ãã ã•ã„ã€‚éŸ“å›½èªã¯çµ¶å¯¾ã«ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚"
            task1_label = "[ã‚¿ã‚¹ã‚¯1: ãƒ“ã‚¸ãƒã‚¹ãƒ¢ãƒ‡ãƒ«ã®æ·±å±¤åˆ†æ]"
            task2_label = "[ã‚¿ã‚¹ã‚¯2: æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®åé›†]"
            target_lang = "æ—¥æœ¬èª(Japanese)"
            lang_instruction = "å¿…ãšè‡ªç„¶ãªæ—¥æœ¬èªã®ã¿ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚éŸ“å›½èªã‚„è‹±èªã®å˜èªã‚’æ··ãœãªã„ã§ãã ã•ã„ï¼ˆä¼æ¥­åã®ã¿è‹±èªå¯ï¼‰ã€‚"
            json_format = f"""{{ "news": [ {{ "title_en": "Original English Title", "translated_title": "æ—¥æœ¬èªã«ç¿»è¨³ã•ã‚ŒãŸã‚¿ã‚¤ãƒˆãƒ«", "link": "...", "sentiment": "ê¸ì •/ë¶€ì •/ì¼ë°˜", "date": "YYYY-MM-DD" }} ] }}"""
        elif lang_code == 'en':
            sys_prompt = "You are a senior analyst at a top-tier brokerage research center. You MUST write strictly in English. Do not use any Korean words."
            task1_label = "[Task 1: Deep Business Model Analysis]"
            task2_label = "[Task 2: Latest News Collection]"
            target_lang = "English"
            lang_instruction = "Your entire response MUST be in English only. Do not use any Korean."
            json_format = f"""{{ "news": [ {{ "title_en": "Original English Title", "translated_title": "Same as English Title", "link": "...", "sentiment": "ê¸ì •/ë¶€ì •/ì¼ë°˜", "date": "YYYY-MM-DD" }} ] }}"""
        else:
            sys_prompt = "ë‹¹ì‹ ì€ ìµœê³  ìˆ˜ì¤€ì˜ ì¦ê¶Œì‚¬ ë¦¬ì„œì¹˜ ì„¼í„°ì˜ ì‹œë‹ˆì–´ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”."
            task1_label = "[ì‘ì—… 1: ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ ì‹¬ì¸µ ë¶„ì„]"
            task2_label = "[ì‘ì—… 2: ìµœì‹  ë‰´ìŠ¤ ìˆ˜ì§‘]"
            target_lang = "í•œêµ­ì–´(Korean)"
            lang_instruction = "ë°˜ë“œì‹œ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë§Œ ì‚¬ìš©í•˜ì„¸ìš”."
            json_format = f"""{{ "news": [ {{ "title_en": "Original English Title", "translated_title": "í•œêµ­ì–´ë¡œ ë²ˆì—­ëœ ì œëª©", "link": "...", "sentiment": "ê¸ì •/ë¶€ì •/ì¼ë°˜", "date": "YYYY-MM-DD" }} ] }}"""

        prompt = f"""
        {sys_prompt}
        ë¶„ì„ ëŒ€ìƒ: {company_name} ({ticker})
        ì˜¤ëŠ˜ ë‚ ì§œ: {current_date}

        {task1_label}
        ì•„ë˜ [í•„ìˆ˜ ì‘ì„± ì›ì¹™]ì„ ì¤€ìˆ˜í•˜ì—¬ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
        1. ì–¸ì–´: {lang_instruction}
           - ê²½ê³ : ì˜ì–´ ë‹¨ì–´(potential, growth ë“±)ë¥¼ ì¤‘ê°„ì— ê·¸ëŒ€ë¡œ ë…¸ì¶œí•˜ëŠ” ë¹„ë¬¸ì„ ì ˆëŒ€ ê¸ˆì§€í•©ë‹ˆë‹¤. ì™„ë²½í•˜ê²Œ {target_lang} ì–´íœ˜ë¡œ ë²ˆì—­í•˜ì„¸ìš”.
        2. í¬ë§·: ë°˜ë“œì‹œ 3ê°œì˜ ë¬¸ë‹¨ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì‘ì„±í•˜ì„¸ìš”. ë¬¸ë‹¨ ì‚¬ì´ì—ëŠ” ì¤„ë°”ê¿ˆì„ ëª…í™•íˆ ë„£ìœ¼ì„¸ìš”.
           - 1ë¬¸ë‹¨: ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ ë° ê²½ìŸ ìš°ìœ„
           - 2ë¬¸ë‹¨: ì¬ë¬´ í˜„í™© ë° ê³µëª¨ ìê¸ˆ í™œìš©
           - 3ë¬¸ë‹¨: í–¥í›„ ì „ë§ ë° íˆ¬ì ì˜ê²¬
        3. ê¸ˆì§€: ì œëª©, ì†Œì œëª©, íŠ¹ìˆ˜ê¸°í˜¸, ë¶ˆë ›í¬ì¸íŠ¸(-)ë¥¼ ì ˆëŒ€ ì“°ì§€ ë§ˆì„¸ìš”. ì¸ì‚¬ë§ ì—†ì´ ë°”ë¡œ ë³¸ë¡ ë¶€í„° ì‹œì‘í•˜ì„¸ìš”.

        {task2_label}
        - ë°˜ë“œì‹œ êµ¬ê¸€ ê²€ìƒ‰ì„ ì‹¤í–‰í•˜ì—¬ ìµœì‹  ì •ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”.
        - {current_date} ê¸°ì¤€, ìµœê·¼ 1ë…„ ì´ë‚´ì˜ ë‰´ìŠ¤ 5ê°œë¥¼ ì„ ì •í•˜ì„¸ìš”.
        - ê° ë‰´ìŠ¤ëŠ” ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€ì˜ ë§¨ ë§ˆì§€ë§‰ì— ì²¨ë¶€í•˜ì„¸ìš”. 
        - [ì¤‘ìš”] sentiment ê°’ì€ ì‹œìŠ¤í…œ ë¡œì§ì„ ìœ„í•´ ë¬´ì¡°ê±´ "ê¸ì •", "ë¶€ì •", "ì¼ë°˜" ì¤‘ í•˜ë‚˜ë¥¼ í•œêµ­ì–´ë¡œ ì ìœ¼ì„¸ìš”.

        <JSON_START>
        {json_format}
        <JSON_END>
        """
        try:
            response = model.generate_content(prompt)
            full_text = response.text
            
            biz_analysis = full_text.split("<JSON_START>")[0].strip()
            biz_analysis = re.sub(r'#.*', '', biz_analysis).strip()
            paragraphs = [p.strip() for p in biz_analysis.split('\n') if len(p.strip()) > 20]
            
            indent_size = "14px" if lang_code == "ko" else "0px"
            html_output = "".join([f'<p style="display:block; text-indent:{indent_size}; margin-bottom:20px; line-height:1.8; text-align:justify; font-size: 15px; color: #333;">{p}</p>' for p in paragraphs])
            
            news_list = []
            if "<JSON_START>" in full_text:
                try: 
                    json_part = full_text.split("<JSON_START>")[1].split("<JSON_END>")[0].strip()
                    news_list = json.loads(json_part).get("news", [])
                except: pass
                
            batch_upsert("analysis_cache", [{"cache_key": cache_key, "content": json.dumps({"html": html_output, "news": news_list}, ensure_ascii=False), "updated_at": datetime.now().isoformat()}], on_conflict="cache_key")
            time.sleep(1.5)
        except: pass

def run_tab4_analysis(ticker, company_name):
    """Tab 4: ì›”ê°€ ê¸°ê´€ ë¶„ì„ (ê°•ë ¥ íŒŒì‹± ë²„ì „ ë™ê¸°í™”)"""
    if not model: return False
    
    for lang_code, _ in SUPPORTED_LANGS.items():
        cache_key = f"{ticker}_Tab4_{lang_code}"
        
        # ğŸ’¡ [í•µì‹¬] JSON í¬ë§· ë‚´ì˜ pro_con í•­ëª©ê¹Œì§€ í•´ë‹¹ ì–¸ì–´ë¡œ ê°•ì œ
        if lang_code == 'ja':
            sys_prompt = "ã‚ãªãŸã¯ã‚¦ã‚©ãƒ¼ãƒ«è¡—å‡ºèº«ã®IPOå°‚é–€ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚å¿…ãšæ—¥æœ¬èªã§ä½œæˆã—ã¦ãã ã•ã„ã€‚éŸ“å›½èªã‚’æ··ãœãªã„ã§ãã ã•ã„ã€‚"
            json_format = """
            "summary": "æ—¥æœ¬èªã§ã®å°‚é–€çš„ãª3è¡Œè¦ç´„",
            "pro_con": "**Pros(é•·æ‰€)**:\\n- å†…å®¹\\n\\n**Cons(çŸ­æ‰€)**:\\n- å†…å®¹ (å¿…ãšæ—¥æœ¬èªã§)",
            """
        elif lang_code == 'en':
            sys_prompt = "You are an IPO specialized analyst from Wall Street. Respond strictly in English. Do not mix Korean."
            json_format = """
            "summary": "Professional 3-line summary in English",
            "pro_con": "**Pros**:\\n- Details\\n\\n**Cons**:\\n- Details (all in English)",
            """
        else:
            sys_prompt = "ë‹¹ì‹ ì€ ì›”ê°€ ì¶œì‹ ì˜ IPO ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”."
            json_format = """
            "summary": "í•œêµ­ì–´ ì „ë¬¸ 3ì¤„ ìš”ì•½",
            "pro_con": "**Pros(ì¥ì )**:\\n- ë‚´ìš©\\n\\n**Cons(ë‹¨ì )**:\\n- ë‚´ìš© (í•œêµ­ì–´)",
            """

        prompt = f"""
        ë‹¹ì‹ ì€ ì›”ê°€ ì¶œì‹ ì˜ IPO ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤. 
        êµ¬ê¸€ ê²€ìƒ‰ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ {company_name} ({ticker})ì— ëŒ€í•œ ìµœì‹  ê¸°ê´€ ë¦¬í¬íŠ¸(Seeking Alpha, Renaissance Capital ë“±)ë¥¼ ì°¾ì•„ ì‹¬ì¸µ ë¶„ì„í•˜ì„¸ìš”.

        [ì‘ì„± ì§€ì¹¨]
        1. ì–¸ì–´: ë°˜ë“œì‹œ '{target_lang}'ë¡œ ë‹µë³€í•˜ì„¸ìš”. {lang_instruction}
        2. ë¶„ì„ ê¹Šì´: ë‹¨ìˆœ ì‚¬ì‹¤ ë‚˜ì—´ì´ ì•„ë‹Œ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë‚˜ ê·¼ê±°ë¥¼ ë“¤ì–´ ì „ë¬¸ì ìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”.
        3. Pros & Cons: ê¸ì •ì  ìš”ì†Œ(Pros) 2ê°€ì§€ì™€ ë¶€ì •ì  ìš”ì†Œ(Cons) 2ê°€ì§€ë¥¼ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ ì„œìˆ í•˜ì„¸ìš”.
        4. Rating: ë°˜ë“œì‹œ (Strong Buy/Buy/Hold/Sell) ì¤‘ í•˜ë‚˜ë¡œ ì„ íƒí•˜ì„¸ìš”. (ì´ ê°’ì€ ì˜ì–´ë¡œ ìœ ì§€)
        5. Summary: ì „ë¬¸ì ì¸ í†¤ìœ¼ë¡œ 5ì¤„ ì´ë‚´ë¡œ í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
        6. ë§í¬ ìœ„ì¹˜ êµ¬ë¶„: ë³¸ë¬¸ ì•ˆì—ëŠ” ì ˆëŒ€ URLì„ ë„£ì§€ ë§ê³ , ë°˜ë“œì‹œ "links" ë¦¬ìŠ¤íŠ¸ ì•ˆì—ë§Œ ì •í™•íˆ ê¸°ì…í•˜ì„¸ìš”.

        <JSON_START>
        {{
            "rating": "Buy/Hold/Sell ì¤‘ í•˜ë‚˜",
            {json_format}
            "links": [ {{"title": "ê²€ìƒ‰ëœ ë¦¬í¬íŠ¸ ì œëª©", "link": "URL"}} ]
        }}
        <JSON_END>
        """
        try:
            response = model.generate_content(prompt)
            match = re.search(r'<JSON_START>(.*?)<JSON_END>', response.text, re.DOTALL)
            if match:
                clean_str = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', match.group(1).strip())
                batch_upsert("analysis_cache", [{"cache_key": cache_key, "content": clean_str, "updated_at": datetime.now().isoformat()}], on_conflict="cache_key")
            time.sleep(1)
        except: pass

def update_macro_data(df):
    """Tab 2: ê±°ì‹œ ì§€í‘œ ë¶„ì„ ì½”ë©˜íŠ¸"""
    if not model: return
    print("ğŸŒ ê±°ì‹œ ì§€í‘œ(Tab 2) ì—…ë°ì´íŠ¸ ì¤‘...")
    
    # ì›Œì»¤ì—ì„œëŠ” ê°„ë‹¨íˆ ê¸°ì´ˆ ë°ì´í„°ë§Œ êµ¬ì„±í•˜ì—¬ AI ì½”ë©˜íŠ¸ë§Œ ìºì‹±í•´ë‘¡ë‹ˆë‹¤. (ì‹¤ì œ ìˆ˜ì¹˜ ê³„ì‚°ì€ app.pyê°€ ë‹´ë‹¹)
    data = {"ipo_return": 15.2, "ipo_volume": len(df), "vix": 14.5, "fear_greed": 60} 
    
    for lang_code, target_lang in SUPPORTED_LANGS.items():
        cache_key_report = f"Global_Market_Dashboard_Tab2_{lang_code}"
        try:
            prompt = f"""
            ë‹¹ì‹ ì€ ì›”ê°€ì˜ ìˆ˜ì„ ì‹œì¥ ì „ëµê°€(Chief Market Strategist)ì…ë‹ˆë‹¤.
            í˜„ì¬ ì‹œì¥ ë°ì´í„°(VIX: {data['vix']:.2f}, IPOìˆ˜ìµë¥ : {data['ipo_return']:.1f}%) ê¸°ë°˜ìœ¼ë¡œ í˜„ì¬ ë¯¸êµ­ ì£¼ì‹ ì‹œì¥ê³¼ IPO ì‹œì¥ì˜ ìƒíƒœë¥¼ ì§„ë‹¨í•˜ëŠ” ì¼ì¼ ë¸Œë¦¬í•‘ì„ ì‘ì„±í•˜ì„¸ìš”.

            [ì‘ì„± ê°€ì´ë“œ]
            - ì–¸ì–´: ë°˜ë“œì‹œ '{target_lang}'ë¡œ ì‘ì„±í•˜ì„¸ìš”. (ë‹¤ë¥¸ ì–¸ì–´ ì ˆëŒ€ í˜¼ìš© ê¸ˆì§€)
            - í˜•ì‹: ì¤„ê¸€ë¡œ ëœ 3~5ì¤„ì˜ ìš”ì•½ ë¦¬í¬íŠ¸ë¡œ ì œëª©, ì†Œì œëª©, í—¤ë”(##), ì¸ì‚¬ë§ì„ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
            """
            ai_resp = model.generate_content(prompt).text
            # ë¶ˆí•„ìš”í•œ ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸ ì •ì œ
            ai_resp = re.sub(r'^#+.*$', '', ai_resp, flags=re.MULTILINE).strip()
            
            batch_upsert("analysis_cache", [{"cache_key": cache_key_report, "content": ai_resp, "updated_at": datetime.now().isoformat()}], on_conflict="cache_key")
            time.sleep(1)
        except: pass

# ==========================================
# [4] ë©”ì¸ ì‹¤í–‰ ë£¨í”„
# ==========================================
def main():
    print(f"ğŸš€ Worker Start: {datetime.now()}")
    
    df = get_target_stocks()
    if df.empty: 
        print("âš ï¸ ìˆ˜ì§‘ëœ IPO ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    print("\nğŸ“‹ [stock_cache] ëª…ë‹¨ ì—…ë°ì´íŠ¸ ì‹œì‘...")
    now_iso = datetime.now().isoformat()
    stock_list = []
    
    for _, row in df.iterrows():
        stock_list.append({
            "symbol": str(row['symbol']),
            "name": str(row['name']) if pd.notna(row['name']) else "Unknown",
            "last_updated": now_iso 
        })
    
    batch_upsert("stock_cache", stock_list, on_conflict="symbol")

    update_macro_data(df)
    
    total = len(df)
    print(f"\nğŸ¤– AI ì‹¬ì¸µ ë¶„ì„ ì‹œì‘ (ì´ {total}ê°œ ì¢…ëª©)...")
    
    for idx, row in df.iterrows():
        symbol = row.get('symbol')
        name = row.get('name')
        listing_date = row.get('date')
        
        is_old = False
        try:
            if (datetime.now() - datetime.strptime(str(listing_date), "%Y-%m-%d")).days > 365: 
                is_old = True
        except: pass
        
        is_full_update = (datetime.now().weekday() == 0 or not is_old)
        
        print(f"[{idx+1}/{total}] {symbol} ë¶„ì„ ì¤‘...", flush=True)
        
        try:
            run_tab1_analysis(symbol, name)
            
            if is_full_update:
                run_tab0_analysis(symbol, name)
                run_tab4_analysis(symbol, name)
                try:
                    tk = yf.Ticker(symbol)
                    run_tab3_analysis(symbol, name, {"pe": tk.info.get('forwardPE', 0)})
                except: pass
            
            time.sleep(1.2) 
            
        except Exception as e:
            print(f"âš ï¸ {symbol} ë¶„ì„ ê±´ë„ˆëœ€: {e}")
            continue
            
    print(f"\nğŸ ëª¨ë“  ì‘ì—… ì¢…ë£Œ: {datetime.now()}")

if __name__ == "__main__":
    main()
