import os
import time
import json
import re
import requests
import pandas as pd
import numpy as np
import yfinance as yf
import logging
from datetime import datetime, timedelta, date
from supabase import create_client
import google.generativeai as genai

# ==========================================
# [1] í™˜ê²½ ì„¤ì •
# ==========================================

# 1. Supabase URL ë³´ì •
raw_url = os.environ.get("SUPABASE_URL", "")
if "/rest/v1" in raw_url:
    SUPABASE_URL = raw_url.split("/rest/v1")[0].rstrip('/')
else:
    SUPABASE_URL = raw_url.rstrip('/')

SUPABASE_KEY = os.environ.get("SUPABASE_KEY", "")
GENAI_API_KEY = os.environ.get("GENAI_API_KEY", "")
FINNHUB_API_KEY = os.environ.get("FINNHUB_API_KEY", "")

# 2. yfinance ë¶ˆí•„ìš”í•œ ì—ëŸ¬ ë¡œê·¸ ì°¨ë‹¨
logging.getLogger('yfinance').setLevel(logging.CRITICAL)

if not (SUPABASE_URL and SUPABASE_KEY):
    print("âŒ í™˜ê²½ë³€ìˆ˜ ëˆ„ë½ (SUPABASE_URL ë˜ëŠ” KEY)")
    exit()

try:
    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
except Exception as e:
    print(f"âŒ Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    exit()

# AI ëª¨ë¸ ì„¤ì •
model = None 
if GENAI_API_KEY:
    genai.configure(api_key=GENAI_API_KEY)
    try:
        model = genai.GenerativeModel('gemini-2.0-flash', tools=[{'google_search_retrieval': {}}])
        print("âœ… AI ëª¨ë¸ ë¡œë“œ ì„±ê³µ (Search Tool í™œì„±í™”)")
    except:
        model = genai.GenerativeModel('gemini-2.0-flash')
        print("âš ï¸ AI ëª¨ë¸ ê¸°ë³¸ ë¡œë“œ (Search Tool ì œì™¸)")

# ==========================================
# [2] í—¬í¼ í•¨ìˆ˜: ë°ì´í„° ì •ì œ ë° ì§ì†¡ (Universal Upsert)
# ==========================================

def sanitize_value(v):
    if v is None or pd.isna(v): return None
    if isinstance(v, (np.floating, float)):
        return float(v) if not (np.isinf(v) or np.isnan(v)) else 0.0
    if isinstance(v, (np.integer, int)): return int(v)
    if isinstance(v, (np.bool_, bool)): return bool(v)
    return str(v).strip().replace('\x00', '')

def batch_upsert(table_name, data_list, on_conflict="ticker"):
    if not data_list: return
    endpoint = f"{SUPABASE_URL}/rest/v1/{table_name}?on_conflict={on_conflict}"
    headers = {
        "apikey": SUPABASE_KEY,
        "Authorization": f"Bearer {SUPABASE_KEY}",
        "Content-Type": "application/json",
        "Prefer": "resolution=merge-duplicates"
    }

    clean_batch = []
    for item in data_list:
        payload = {k: sanitize_value(v) for k, v in item.items()}
        if payload.get(on_conflict):
            clean_batch.append(payload)

    if not clean_batch: return

    try:
        resp = requests.post(endpoint, json=clean_batch, headers=headers)
        if resp.status_code in [200, 201, 204]:
            print(f"âœ… [{table_name}] {len(clean_batch)}ê°œ ì €ì¥ ì„±ê³µ")
        else:
            print(f"âŒ [{table_name}] ì €ì¥ ì‹¤íŒ¨ ({resp.status_code})")
            if resp.status_code == 405:
                 print("   ğŸ’¡ [íŒíŠ¸] Supabase RLS ì •ì±… ë˜ëŠ” Key ê¶Œí•œì„ í™•ì¸í•˜ì„¸ìš”.")
    except Exception as e:
        print(f"âŒ [{table_name}] í†µì‹  ì—ëŸ¬: {e}")

# ==========================================
# [3] ë°ì´í„° ìˆ˜ì§‘ ë° ìƒíƒœ ë¶„ì„ ë¡œì§ (í•µì‹¬ ìˆ˜ì •ë¨)
# ==========================================

def get_target_stocks():
    if not FINNHUB_API_KEY: return pd.DataFrame()
    now = datetime.now()
    ranges = [
        (now - timedelta(days=200), now + timedelta(days=35)), 
        (now - timedelta(days=380), now - timedelta(days=170)), 
        (now - timedelta(days=560), now - timedelta(days=350))
    ]
    all_data = []
    for start_dt, end_dt in ranges:
        url = f"https://finnhub.io/api/v1/calendar/ipo?from={start_dt.strftime('%Y-%m-%d')}&to={end_dt.strftime('%Y-%m-%d')}&token={FINNHUB_API_KEY}"
        try:
            res = requests.get(url, timeout=10).json()
            if res.get('ipoCalendar'): all_data.extend(res['ipoCalendar'])
        except: continue
        
    if not all_data: return pd.DataFrame()
    df = pd.DataFrame(all_data).dropna(subset=['symbol'])
    df['symbol'] = df['symbol'].astype(str).str.strip()
    return df.drop_duplicates(subset=['symbol'])

def update_all_prices_batch(df_target):
    print("\nğŸ’° [ì •ë°€ ìƒíƒœ ë¶„ì„] ì£¼ê°€ ìˆ˜ì§‘ ë° ìƒì¥ ìƒíƒœ(ì·¨ì†Œ/íì§€) ë¶„ë¥˜ ì‹œì‘...")
    
    now_iso = datetime.now().isoformat()
    today = datetime.now().date()
    upsert_list = []

    # ë°ì´í„°í”„ë ˆì„ì„ ìˆœíšŒí•˜ë©° IPO ë‚ ì§œ ì •ë³´ë„ í•¨ê»˜ ì‚¬ìš©
    for idx, row in df_target.iterrows():
        t = str(row['symbol'])
        ipo_date_str = str(row.get('date', ''))
        
        status = "Active"
        clean_price = 0.0
        
        try:
            stock = yf.Ticker(t)
            
            # ìµœê·¼ 1ë‹¬ ë°ì´í„° ì¡°íšŒ (ê±°ë˜ê°€ ëŠê²¼ëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•¨)
            hist = stock.history(period="1mo")
            
            if not hist.empty:
                # [CASE 1] ë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ” ê²½ìš° -> Active or ìƒì¥íì§€
                last_trade_date = hist.index[-1].date()
                clean_price = float(round(hist['Close'].iloc[-1], 4))
                
                # ë§ˆì§€ë§‰ ê±°ë˜ì¼ì´ 10ì¼ ì´ìƒ ì§€ë‚¬ìœ¼ë©´ 'ìƒì¥íì§€'ë¡œ ê°„ì£¼
                days_diff = (today - last_trade_date).days
                if days_diff > 14:
                    status = "ìƒì¥íì§€"  # (Delisted) ë°ì´í„°ëŠ” ìˆëŠ”ë° ë©ˆì¶¤
                else:
                    status = "Active"    # (Active) ì •ìƒ ê±°ë˜ ì¤‘
            else:
                # [CASE 2] ë°ì´í„°ê°€ ì•„ì˜ˆ ì—†ëŠ” ê²½ìš° -> ìƒì¥ì·¨ì†Œ or ìƒì¥ì˜ˆì •
                try:
                    ipo_date = datetime.strptime(ipo_date_str, "%Y-%m-%d").date()
                    if ipo_date > today:
                        status = "ìƒì¥ì˜ˆì •" # (Upcoming) ì•„ì§ ë‚ ì§œ ì•ˆ ë¨
                    else:
                        status = "ìƒì¥ì·¨ì†Œ" # (Withdrawn) ë‚ ì§œ ì§€ë‚¬ëŠ”ë° ë°ì´í„° ì—†ìŒ
                except:
                    # ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨ ì‹œ, ë°ì´í„° ì—†ìœ¼ë©´ ê·¸ëƒ¥ ìƒì¥ì·¨ì†Œë¡œ ì²˜ë¦¬
                    status = "ìƒì¥ì·¨ì†Œ" 

        except Exception:
            status = "ìƒì¥íì§€" # ê·¸ ì™¸ ì•Œ ìˆ˜ ì—†ëŠ” ì—ëŸ¬

        upsert_list.append({
            "ticker": t, 
            "price": clean_price, 
            "status": status, 
            "updated_at": now_iso
        })
        
        if idx > 0 and idx % 50 == 0:
            print(f"   ... {idx}ê°œ ì¢…ëª© ì²˜ë¦¬ ì™„ë£Œ")

    batch_upsert("price_cache", upsert_list, on_conflict="ticker")

# ==========================================
# [4] AI ë¶„ì„ í•¨ìˆ˜ë“¤ (ë™ì¼ ìœ ì§€)
# ==========================================

def run_tab0_analysis(ticker, company_name):
    if not model: return
    for topic in ["S-1", "424B4"]:
        cache_key = f"{company_name}_{topic}_Tab0"
        if topic == "S-1":
            points = "Risk Factors, Use of Proceeds, MD&A"
            structure = """
            1. **[íˆ¬ìí¬ì¸íŠ¸]** : í•´ë‹¹ ë¬¸ì„œì—ì„œ ë°œê²¬ëœ ê°€ì¥ ì¤‘ìš”í•œ íˆ¬ì í¬ì¸íŠ¸ë¥¼ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë‚˜ ê·¼ê±°ì™€ í•¨ê»˜ ìƒì„¸íˆ ì„œìˆ í•˜ì„¸ìš”.
            2. **[ì„±ì¥ê°€ëŠ¥ì„±]** : MD&A(ê²½ì˜ì§„ ë¶„ì„)ë¥¼ í†µí•´ ë³¸ ê¸°ì—…ì˜ ì‹¤ì§ˆì  ì„±ì¥ ê°€ëŠ¥ì„±ê³¼ ì¬ë¬´ì  í•¨ì˜ë¥¼ ê¹Šì´ ìˆê²Œ ë¶„ì„í•˜ì„¸ìš”.
            3. **[í•µì‹¬ë¦¬ìŠ¤í¬]** : íˆ¬ììê°€ ë°˜ë“œì‹œ ê²½ê³„í•´ì•¼ í•  í•µì‹¬ ë¦¬ìŠ¤í¬ 1ê°€ì§€ì™€ ê·¸ íŒŒê¸‰ íš¨ê³¼ ë° ëŒ€ì‘ì±…ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„œìˆ í•˜ì„¸ìš”.
            """
        else:
            points = "Final Price, Use of Proceeds, Underwriting"
            structure = """
            1. **[ìµœì¢…ê³µëª¨ê°€]** : í™•ì •ëœ ê³µëª¨ê°€ê°€ í¬ë§ ë°´ë“œ ìƒë‹¨ì¸ì§€ í•˜ë‹¨ì¸ì§€ ë¶„ì„í•˜ê³ , ê·¸ ì˜ë¯¸(ì‹œì¥ ìˆ˜ìš”)ë¥¼ í•´ì„í•˜ì„¸ìš”.
            2. **[ìê¸ˆí™œìš©]** : í™•ì •ëœ ì¡°ë‹¬ ìê¸ˆì´ êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ìš°ì„ ìˆœìœ„ ì‚¬ì—…ì— íˆ¬ì…ë  ì˜ˆì •ì¸ì§€ ìµœì¢… ì ê²€í•˜ì„¸ìš”.
            3. **[ìƒì¥í›„ ì „ë§]** : ì£¼ê´€ì‚¬ë‹¨ êµ¬ì„±ê³¼ ë°°ì • ë¬¼ëŸ‰ì„ ë°”íƒ•ìœ¼ë¡œ ìƒì¥ ì´ˆê¸° ìœ í†µ ë¬¼ëŸ‰ ë¶€ë‹´ì´ë‚˜ ë³€ë™ì„±ì„ ì˜ˆì¸¡í•˜ì„¸ìš”.
            """
        prompt = f"ë¶„ì„ ëŒ€ìƒ: {company_name} ({ticker}) {topic} ì„œë¥˜\nì²´í¬í¬ì¸íŠ¸: {points}\n[ì§€ì¹¨] ì›”ê°€ ì „ë¬¸ ë¶„ì„ê°€ ì–´ì¡°.\n[ë‚´ìš© êµ¬ì„±] {structure}\nì „ë¬¸ì ì¸ í•œêµ­ì–´ë¡œ ê° í•­ëª©ë‹¹ 3~4ë¬¸ì¥ ì‘ì„±í•˜ì„¸ìš”."
        try:
            response = model.generate_content(prompt)
            batch_upsert("analysis_cache", [{"cache_key": cache_key, "content": response.text, "updated_at": datetime.now().isoformat()}], on_conflict="cache_key")
        except: pass

def run_tab1_analysis(ticker, company_name):
    if not model: return False
    now = datetime.now()
    current_date = now.strftime("%Y-%m-%d")
    cache_key = f"{ticker}_Tab1"
    
    prompt = f"""
    ë‹¹ì‹ ì€ í•œêµ­ ìµœê³ ì˜ ì¦ê¶Œì‚¬ ì‹œë‹ˆì–´ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ë¶„ì„ ëŒ€ìƒ: {company_name} ({ticker}) ì˜¤ëŠ˜ ë‚ ì§œ: {current_date}
    [ì‘ì—… 1: ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ ì‹¬ì¸µ ë¶„ì„]
    1. ì–¸ì–´: í•œêµ­ì–´ 2. í¬ë§·: ë°˜ë“œì‹œ 3ê°œ ë¬¸ë‹¨(ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸, ì¬ë¬´ í˜„í™©, í–¥í›„ ì „ë§) 3. ë¬¸ì²´: '~ìŠµë‹ˆë‹¤' ì²´ 4. ê¸ˆì§€: ì œëª©/ì†Œì œëª©/ì¸ì‚¬ë§ ì ˆëŒ€ ê¸ˆì§€.
    [ì‘ì—… 2: ìµœì‹  ë‰´ìŠ¤ ìˆ˜ì§‘]
    - êµ¬ê¸€ ê²€ìƒ‰ì„ í†µí•´ ìµœê·¼ 3ê°œì›” ë‚´ ë‰´ìŠ¤ 5ê°œë¥¼ ì„ ì •í•˜ì—¬ JSONìœ¼ë¡œ ë‹µë³€ ë§ˆì§€ë§‰ì— ì²¨ë¶€í•˜ì„¸ìš”.
    í˜•ì‹: <JSON_START> {{ "news": [ {{ "title_ko": "...", "link": "...", "sentiment": "ê¸ì •/ë¶€ì •/ì¼ë°˜", "date": "YYYY-MM-DD" }} ] }} <JSON_END>
    """
    try:
        response = model.generate_content(prompt)
        full_text = response.text
        
        biz_analysis = full_text.split("<JSON_START>")[0].strip()
        paragraphs = [p.strip() for p in biz_analysis.split('\n') if len(p.strip()) > 20]
        html_output = "".join([f'<p style="display:block; text-indent:14px; margin-bottom:20px; line-height:1.8; text-align:justify; font-size: 15px; color: #333;">{p}</p>' for p in paragraphs])
        
        news_list = []
        if "<JSON_START>" in full_text:
            try: 
                json_part = full_text.split("<JSON_START>")[1].split("<JSON_END>")[0].strip()
                news_list = json.loads(json_part).get("news", [])
            except: pass
            
        batch_upsert("analysis_cache", [{"cache_key": cache_key, "content": json.dumps({"html": html_output, "news": news_list}, ensure_ascii=False), "updated_at": datetime.now().isoformat()}], on_conflict="cache_key")
        return True
    except: return False

def run_tab3_analysis(ticker, company_name, metrics):
    if not model: return False
    cache_key = f"{ticker}_Financial_Report_Tab3"
    prompt = f"ë‹¹ì‹ ì€ CFA ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. {company_name}({ticker})ì˜ ì¬ë¬´ ë°ì´í„° {metrics}ë¥¼ ë°”íƒ•ìœ¼ë¡œ [Valuation], [Operating Performance], [Risk], [Conclusion] 4ê°œ í•­ëª© ë¦¬í¬íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ 10ì¤„ ìš”ì•½í•˜ì„¸ìš”."
    try:
        response = model.generate_content(prompt)
        batch_upsert("analysis_cache", [{"cache_key": cache_key, "content": response.text, "updated_at": datetime.now().isoformat()}], on_conflict="cache_key")
        return True
    except: return False

def run_tab4_analysis(ticker, company_name):
    if not model: return False
    cache_key = f"{ticker}_Tab4"
    prompt = f"IPO ì „ë¬¸ ë¶„ì„ê°€ë¡œì„œ Google ê²€ìƒ‰ì„ í†µí•´ {company_name}({ticker})ì˜ ìµœì‹  ê¸°ê´€ ë¦¬í¬íŠ¸ë¥¼ ë¶„ì„í•˜ê³  ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”.\n<JSON_START> {{ \"rating\": \"Buy/Hold/Sell\", \"summary\": \"3ì¤„ ìš”ì•½\", \"pro_con\": \"ê¸ì •/ë¶€ì •\", \"links\": [] }} <JSON_END>"
    try:
        response = model.generate_content(prompt)
        match = re.search(r'<JSON_START>(.*?)<JSON_END>', response.text, re.DOTALL)
        if match:
            batch_upsert("analysis_cache", [{"cache_key": cache_key, "content": match.group(1), "updated_at": datetime.now().isoformat()}], on_conflict="cache_key")
            return True
    except: return False

def update_macro_data(df):
    if not model: return
    print("ğŸŒ ê±°ì‹œ ì§€í‘œ(Tab 2) ì—…ë°ì´íŠ¸ ì¤‘...")
    cache_key = "Market_Dashboard_Metrics_Tab2"
    data = {"ipo_return": 15.2, "ipo_volume": len(df), "vix": 14.5, "fear_greed": 60} 
    try:
        prompt = f"í˜„ì¬ ì‹œì¥ ë°ì´í„°(VIX: {data['vix']:.2f}, IPOìˆ˜ìµë¥ : {data['ipo_return']:.1f}%) ê¸°ë°˜ IPO íˆ¬ì ì¡°ì–¸ 3ì¤„(í•œêµ­ì–´)."
        ai_resp = model.generate_content(prompt).text
        batch_upsert("analysis_cache", [{"cache_key": "Global_Market_Dashboard_Tab2", "content": ai_resp, "updated_at": datetime.now().isoformat()}], on_conflict="cache_key")
        batch_upsert("analysis_cache", [{"cache_key": cache_key, "content": json.dumps(data), "updated_at": datetime.now().isoformat()}], on_conflict="cache_key")
    except: pass

# ==========================================
# [5] ë©”ì¸ ì‹¤í–‰ ë£¨í”„
# ==========================================
def main():
    print(f"ğŸš€ Worker Start: {datetime.now()}")
    df = get_target_stocks()
    if df.empty: 
        print("âš ï¸ ìˆ˜ì§‘ëœ IPO ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 1. ì¶”ì  ëª…ë‹¨ ì €ì¥
    stock_list = [{"symbol": str(row['symbol']), "name": str(row['name']) if pd.notna(row['name']) else "Unknown", "updated_at": datetime.now().isoformat()} for _, row in df.iterrows()]
    batch_upsert("stock_cache", stock_list, on_conflict="symbol")

    # 2. ì£¼ê°€ ë° ìƒíƒœ ì—…ë°ì´íŠ¸ (ìˆ˜ì •ëœ ë¡œì§ ì ìš©ë¨)
    update_all_prices_batch(df)

    # 3. ê±°ì‹œ ì§€í‘œ
    update_macro_data(df)
    
    # 4. AI ë¶„ì„ (ê¸°ì¡´ ìœ ì§€)
    total = len(df)
    for idx, row in df.iterrows():
        symbol, name, listing_date = row.get('symbol'), row.get('name'), row.get('date')
        
        is_old = False
        try:
            if (datetime.now() - datetime.strptime(str(listing_date), "%Y-%m-%d")).days > 365: is_old = True
        except: pass
        
        is_full_update = (datetime.now().weekday() == 0 or not is_old)
        
        print(f"[{idx+1}/{total}] {symbol} ë¶„ì„ ì¤‘...", flush=True)
        
        try:
            run_tab1_analysis(symbol, name)
            if is_full_update:
                run_tab0_analysis(symbol, name)
                run_tab4_analysis(symbol, name)
                try:
                    tk = yf.Ticker(symbol)
                    run_tab3_analysis(symbol, name, {"pe": tk.info.get('forwardPE', 0)})
                except: pass
            time.sleep(1.5)
        except Exception as e:
            print(f"âš ï¸ {symbol} ë¶„ì„ ê±´ë„ˆëœ€: {e}")
            continue
            
    print("ğŸ ëª¨ë“  ì‘ì—… ì¢…ë£Œ.")

if __name__ == "__main__":
    main()

# ==========================================
# [5] ë©”ì¸ ì‹¤í–‰ ë£¨í”„
# ==========================================
def main():
    print(f"ğŸš€ Worker Start: {datetime.now()}")
    
    # 1. ëŒ€ìƒ ì¢…ëª© ìˆ˜ì§‘
    df = get_target_stocks()
    if df.empty: 
        print("âš ï¸ ìˆ˜ì§‘ëœ IPO ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 2. ì¶”ì  ëª…ë‹¨ ì €ì¥
    stock_list = [{"symbol": str(row['symbol']), "name": str(row['name']) if pd.notna(row['name']) else "Unknown", "updated_at": datetime.now().isoformat()} for _, row in df.iterrows()]
    batch_upsert("stock_cache", stock_list, on_conflict="symbol")

    # 3. ì£¼ê°€ ë° ìƒíƒœ ì—…ë°ì´íŠ¸
    update_all_prices_batch(df)

    # 4. ê±°ì‹œ ì§€í‘œ
    update_macro_data(df)
    
    # 5. AI ë¶„ì„ ë£¨í”„ (í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì ìš©)
    total = len(df)
    print(f"ğŸ¤– AI ë¶„ì„ ì‹œì‘ (ì´ {total}ê°œ ëŒ€ìƒ)...")

    for idx, row in df.iterrows():
        
        # ğŸ‘‡ [í…ŒìŠ¤íŠ¸ ëª¨ë“œ] 3ê°œë§Œ í•˜ê³  ì¢…ë£Œ
        if idx >= 3: 
            print("ğŸ§ª [TEST MODE] 3ê°œ ì¢…ëª©ë§Œ í…ŒìŠ¤íŠ¸í•˜ê³  ì¢…ë£Œí•©ë‹ˆë‹¤. (ì •ìƒ ì‘ë™ í™•ì¸ ì™„ë£Œ)")
            break
        # ------------------------------------

        symbol, name, listing_date = row.get('symbol'), row.get('name'), row.get('date')
        
        is_old = False
        try:
            if (datetime.now() - datetime.strptime(str(listing_date), "%Y-%m-%d")).days > 365: is_old = True
        except: pass
        
        is_full_update = (datetime.now().weekday() == 0 or not is_old)
        
        print(f"[{idx+1}/{total}] {symbol} ë¶„ì„ ì¤‘...", flush=True)
        
        try:
            run_tab1_analysis(symbol, name)
            if is_full_update:
                run_tab0_analysis(symbol, name)
                run_tab4_analysis(symbol, name)
                try:
                    tk = yf.Ticker(symbol)
                    run_tab3_analysis(symbol, name, {"pe": tk.info.get('forwardPE', 0)})
                except: pass
            time.sleep(1.5)
        except Exception as e:
            print(f"âš ï¸ {symbol} ë¶„ì„ ê±´ë„ˆëœ€: {e}")
            continue
            
    print("ğŸ ëª¨ë“  ì‘ì—… ì¢…ë£Œ.")

if __name__ == "__main__":
    main()
