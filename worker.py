import os
import time
import json
import re
import random
import requests
import pandas as pd
import numpy as np
import yfinance as yf
from datetime import datetime, timedelta
from supabase import create_client
import google.generativeai as genai

# ==========================================
# [1] í™˜ê²½ ì„¤ì • (GitHub Secrets ì—°ë™)
# ==========================================
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY")
GENAI_API_KEY = os.environ.get("GENAI_API_KEY")
FINNHUB_API_KEY = os.environ.get("FINNHUB_API_KEY")

# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
if SUPABASE_URL and SUPABASE_KEY:
    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
else:
    print("âŒ Supabase í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    supabase = None

# [AI ëª¨ë¸ ì„¤ì • - ì „ì—­ ë³€ìˆ˜ í•˜ë‚˜ë¡œ í†µì¼]
model = None # ì´ˆê¸°í™”
if GENAI_API_KEY:
    genai.configure(api_key=GENAI_API_KEY)
    try:
        # 2026ë…„ ê¸°ì¤€, 2.0 Flash ëª¨ë¸ì„ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©
        model = genai.GenerativeModel('gemini-2.0-flash') 
        print("âœ… AI ëª¨ë¸ ë¡œë“œ ì„±ê³µ (Gemini 2.0 Flash)")
    except Exception as e:
        print(f"âš ï¸ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        model = None

# ==========================================
# [2] í—¬í¼ í•¨ìˆ˜: ë°ì´í„° ì •ì œ ë° íƒ€ê²Ÿ ì„ ì •
# ==========================================
def clean_value(val):
    """None, NaN, Inf ê°’ì„ 0ìœ¼ë¡œ ì •ì œ"""
    try:
        if val is None or (isinstance(val, (int, float)) and (np.isnan(val) or np.isinf(val))):
            return 0.0
        return float(val)
    except:
        return 0.0

def get_target_stocks():
    """ìƒì¥ ì˜ˆì •(35ì¼) + ì§€ë‚œ 18ê°œì›” ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ"""
    if not FINNHUB_API_KEY: return pd.DataFrame()
    
    now = datetime.now()
    ranges = [
        (now - timedelta(days=200), now + timedelta(days=35)),  
        (now - timedelta(days=380), now - timedelta(days=170)), 
        (now - timedelta(days=560), now - timedelta(days=350))  
    ]
    
    all_data = []
    print("ğŸ“… Target List ìˆ˜ì§‘ ì¤‘...", end=" ")
    for start_dt, end_dt in ranges:
        url = f"https://finnhub.io/api/v1/calendar/ipo?from={start_dt.strftime('%Y-%m-%d')}&to={end_dt.strftime('%Y-%m-%d')}&token={FINNHUB_API_KEY}"
        try:
            time.sleep(0.5) 
            res = requests.get(url, timeout=10).json()
            ipo_list = res.get('ipoCalendar', [])
            if ipo_list: all_data.extend(ipo_list)
        except: continue
    
    if not all_data: return pd.DataFrame()
    
    df = pd.DataFrame(all_data)
    
    # [í•µì‹¬ ìˆ˜ì •] None ë° ì˜ëª»ëœ ë°ì´í„° í•„í„°ë§ ê°•í™”
    # 1. symbol ì»¬ëŸ¼ì˜ NaN ì œê±°
    df = df.dropna(subset=['symbol'])
    # 2. ë¬¸ìì—´ë¡œ ë³€í™˜ í›„ ê³µë°± ì œê±°
    df['symbol'] = df['symbol'].astype(str).str.strip()
    # 3. ë¹ˆ ë¬¸ìì—´, 'NONE', 'NAN' ì œê±°
    df = df[~df['symbol'].isin(['', 'NONE', 'None', 'nan', 'NAN'])]
    # 4. ì¤‘ë³µ ì œê±°
    df = df.drop_duplicates(subset=['symbol', 'date'])
    df = df.reset_index(drop=True)
    
    print(f"âœ… ì´ {len(df)}ê°œ ìœ íš¨ ì¢…ëª© ë°œê²¬")
    return df

# ==========================================
# [3] í•µì‹¬ AI ë¶„ì„ í•¨ìˆ˜ (ì „ì—­ 'model' ë³€ìˆ˜ ì‚¬ìš©)
# ==========================================

# (Tab 0) ì£¼ìš” ê³µì‹œ ë¶„ì„ (S-1 & 424B4)
def run_tab0_analysis(ticker, company_name):
    if not model: return
    if not ticker or str(ticker).lower() == 'none': return
    
    target_topics = ["S-1", "424B4"]
    for topic in target_topics:
        cache_key = f"{company_name}_{topic}_Tab0"
        
        if topic == "S-1":
            points = "Risk Factors, Use of Proceeds, MD&A"
            structure = """
            1. **[íˆ¬ìí¬ì¸íŠ¸]** : í•´ë‹¹ ë¬¸ì„œì—ì„œ ë°œê²¬ëœ ê°€ì¥ ì¤‘ìš”í•œ íˆ¬ì í¬ì¸íŠ¸ë¥¼ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë‚˜ ê·¼ê±°ì™€ í•¨ê»˜ ìƒì„¸íˆ ì„œìˆ í•˜ì„¸ìš”.
            2. **[ì„±ì¥ê°€ëŠ¥ì„±]** : MD&A(ê²½ì˜ì§„ ë¶„ì„)ë¥¼ í†µí•´ ë³¸ ê¸°ì—…ì˜ ì‹¤ì§ˆì  ì„±ì¥ ê°€ëŠ¥ì„±ê³¼ ì¬ë¬´ì  í•¨ì˜ë¥¼ ê¹Šì´ ìˆê²Œ ë¶„ì„í•˜ì„¸ìš”.
            3. **[í•µì‹¬ë¦¬ìŠ¤í¬]** : íˆ¬ììê°€ ë°˜ë“œì‹œ ê²½ê³„í•´ì•¼ í•  í•µì‹¬ ë¦¬ìŠ¤í¬ 1ê°€ì§€ì™€ ê·¸ íŒŒê¸‰ íš¨ê³¼ ë° ëŒ€ì‘ì±…ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„œìˆ í•˜ì„¸ìš”.
            """
        else: # 424B4
            points = "Final Price, Use of Proceeds, Underwriting"
            structure = """
            1. **[ìµœì¢…ê³µëª¨ê°€]** : í™•ì •ëœ ê³µëª¨ê°€ê°€ í¬ë§ ë°´ë“œ ìƒë‹¨ì¸ì§€ í•˜ë‹¨ì¸ì§€ ë¶„ì„í•˜ê³ , ê·¸ ì˜ë¯¸(ì‹œì¥ ìˆ˜ìš”)ë¥¼ í•´ì„í•˜ì„¸ìš”.
            2. **[ìê¸ˆí™œìš©]** : í™•ì •ëœ ì¡°ë‹¬ ìê¸ˆì´ êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ìš°ì„ ìˆœìœ„ ì‚¬ì—…ì— íˆ¬ì…ë  ì˜ˆì •ì¸ì§€ ìµœì¢… ì ê²€í•˜ì„¸ìš”.
            3. **[ìƒì¥í›„ ì „ë§]** : ì£¼ê´€ì‚¬ë‹¨ êµ¬ì„±ê³¼ ë°°ì • ë¬¼ëŸ‰ì„ ë°”íƒ•ìœ¼ë¡œ ìƒì¥ ì´ˆê¸° ìœ í†µ ë¬¼ëŸ‰ ë¶€ë‹´ì´ë‚˜ ë³€ë™ì„±ì„ ì˜ˆì¸¡í•˜ì„¸ìš”.
            """

        prompt = f"""
        ë¶„ì„ ëŒ€ìƒ: {company_name} ({ticker})ì˜ {topic} ì„œë¥˜
        ì²´í¬í¬ì¸íŠ¸: {points}
        
        [ì§€ì¹¨]
        ë‹¹ì‹ ì€ ì›”ê°€ ì¶œì‹ ì˜ ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì¸ì‚¬ë§ ì—†ì´ ë°”ë¡œ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.
        
        [ë‚´ìš© êµ¬ì„±]
        {structure}
        
        ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ì ì¸ ì–´ì¡°ì˜ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”. (ê° í•­ëª©ë‹¹ 3~4ë¬¸ì¥)
        """
        
        try:
            response = model.generate_content(prompt)
            supabase.table("analysis_cache").upsert([
                {
                    "cache_key": cache_key,
                    "content": response.text,
                    "updated_at": datetime.now().isoformat()
                }
            ], on_conflict="cache_key").execute()
        except Exception as e:
            # 404 ì—ëŸ¬ê°€ ë‚˜ë„ ì¡°ìš©íˆ ë„˜ì–´ê°€ë„ë¡ ì²˜ë¦¬
            pass

# (Tab 1) ë¹„ì¦ˆë‹ˆìŠ¤ & ë‰´ìŠ¤ ë¶„ì„
def run_tab1_analysis(ticker, company_name):
    if not model: return False
    if not ticker or str(ticker).lower() == 'none': return False
    cache_key = f"{ticker}_Tab1"
    
    prompt = f"""
    ë‹¹ì‹ ì€ í•œêµ­ ìµœê³ ì˜ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ë¶„ì„ ëŒ€ìƒ: {company_name} ({ticker})
    
    [ì‘ì—… 1: ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ ì‹¬ì¸µ ë¶„ì„]
    - ì–¸ì–´: í•œêµ­ì–´
    - í¬ë§·: 3ê°œ ë¬¸ë‹¨ (1.ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸/ê²½ìŸìš°ìœ„, 2.ì¬ë¬´í˜„í™©/ìê¸ˆí™œìš©, 3.í–¥í›„ì „ë§/ë¦¬ìŠ¤í¬)
    - ì¸ì‚¬ë§ ìƒëµí•˜ê³  ë°”ë¡œ ë³¸ë¡  ì‹œì‘.

    [ì‘ì—… 2: ìµœì‹  ë‰´ìŠ¤ ìˆ˜ì§‘]
    - Google ê²€ìƒ‰ ë„êµ¬ ì‚¬ìš© ê°€ëŠ¥ì‹œ í™œìš©í•˜ì—¬ ìµœì‹  ë‰´ìŠ¤ 5ê°œ ìˆ˜ì§‘ (ë¶ˆê°€ëŠ¥ì‹œ ì•Œê³  ìˆëŠ” ì •ë³´ í™œìš©)
    - JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€ ë§ˆì§€ë§‰ì— ì²¨ë¶€í•˜ì„¸ìš”.
    í˜•ì‹: <JSON_START> {{ "news": [ {{ "title_en": "...", "title_ko": "...", "link": "...", "sentiment": "ê¸ì •/ë¶€ì •/ì¼ë°˜", "date": "YYYY-MM-DD" }} ] }} <JSON_END>
    """
    
    try:
        response = model.generate_content(prompt)
        full_text = response.text
        
        biz_analysis = full_text.split("<JSON_START>")[0].strip()
        paragraphs = [p.strip() for p in biz_analysis.split('\n') if len(p.strip()) > 20]
        html_output = "".join([f'<p style="display:block; text-indent:14px; margin-bottom:20px; line-height:1.8; text-align:justify; font-size: 15px; color: #333;">{p}</p>' for p in paragraphs])
        
        news_list = []
        if "<JSON_START>" in full_text:
            try:
                json_str = full_text.split("<JSON_START>")[1].split("<JSON_END>")[0].strip()
                news_list = json.loads(json_str).get("news", [])
                for n in news_list: 
                    if n['sentiment'] == "ê¸ì •": n['bg'], n['color'] = "#e6f4ea", "#1e8e3e"
                    elif n['sentiment'] == "ë¶€ì •": n['bg'], n['color'] = "#fce8e6", "#d93025"
                    else: n['bg'], n['color'] = "#f1f3f4", "#5f6368"
            except: pass

        supabase.table("analysis_cache").upsert([
            {
                "cache_key": cache_key,
                "content": json.dumps({"html": html_output, "news": news_list}, ensure_ascii=False),
                "updated_at": datetime.now().isoformat()
            }
        ], on_conflict="cache_key").execute()
        return True
    except Exception as e:
        return False

# (Tab 3) ì¬ë¬´ ë¶„ì„ AI
def run_tab3_analysis(ticker, company_name, metrics):
    if not model: return False
    if not ticker or str(ticker).lower() == 'none': return False
    cache_key = f"{ticker}_Financial_Report_Tab3"
    
    prompt = f"""
    ë‹¹ì‹ ì€ CFA ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì•„ë˜ ì¬ë¬´ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ {company_name} ({ticker}) íˆ¬ì ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
    [ì¬ë¬´ ë°ì´í„°] {metrics}
    [ê°€ì´ë“œ]
    - ì–¸ì–´: í•œêµ­ì–´
    - í˜•ì‹: [Valuation], [Operating Performance], [Risk], [Conclusion] 4ê°œ ì†Œì œëª© ì‚¬ìš©.
    - ë¶„ëŸ‰: 10ì¤„ ë‚´ì™¸ ìš”ì•½.
    """
    try:
        response = model.generate_content(prompt)
        supabase.table("analysis_cache").upsert([
            {
                "cache_key": cache_key,
                "content": response.text,
                "updated_at": datetime.now().isoformat()
            }
        ], on_conflict="cache_key").execute()
        return True
    except Exception as e:
        return False

# (Tab 4) ê¸°ê´€ í‰ê°€ AI
def run_tab4_analysis(ticker, company_name):
    if not model: return False
    if not ticker or str(ticker).lower() == 'none': return False
    cache_key = f"{ticker}_Tab4"
    
    prompt = f"""
    ë‹¹ì‹ ì€ IPO ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤. Google ê²€ìƒ‰ì„ í†µí•´ {company_name} ({ticker})ì˜ ìµœì‹  ê¸°ê´€ ë¦¬í¬íŠ¸(Seeking Alpha, Renaissance Capital ë“±)ë¥¼ ë¶„ì„í•˜ì„¸ìš”.
    [ì¶œë ¥ í¬ë§· JSON]
    <JSON_START>
    {{
        "rating": "Buy/Hold/Sell",
        "summary": "3ì¤„ ìš”ì•½ (í•œêµ­ì–´)",
        "pro_con": "**ê¸ì •**: ... \\n **ë¶€ì •**: ...",
        "links": [ {{"title": "Title", "link": "URL"}} ]
    }}
    <JSON_END>
    """
    try:
        response = model.generate_content(prompt)
        text = response.text
        
        json_match = re.search(r'<JSON_START>(.*?)<JSON_END>', text, re.DOTALL)
        if json_match:
            json_str = json_match.group(1).strip()
            result_data = json.loads(re.sub(r'[\x00-\x1f\x7f-\x9f]', '', json_str), strict=False)
            
            supabase.table("analysis_cache").upsert([
                {
                    "cache_key": cache_key,
                    "content": json.dumps(result_data, ensure_ascii=False),
                    "updated_at": datetime.now().isoformat()
                }
            ], on_conflict="cache_key").execute()
            return True
    except Exception as e:
        return False
    return False

# (Tab 2) ê±°ì‹œ ì§€í‘œ ì—…ë°ì´íŠ¸
def update_macro_data(df_calendar):
    if not model: return
    print("ğŸŒ ê±°ì‹œ ì§€í‘œ(Tab 2) ì—…ë°ì´íŠ¸ ì¤‘...")
    cache_key = "Market_Dashboard_Metrics_Tab2"
    data = {"ipo_return": 0.0, "ipo_volume": 0, "unprofitable_pct": 0, "withdrawal_rate": 0, "vix": 0.0, "buffett_val": 0.0, "pe_ratio": 0.0, "fear_greed": 50}
    
    try:
        today = datetime.now()
        if not df_calendar.empty:
            df_calendar['ê³µëª¨ì¼_dt'] = pd.to_datetime(df_calendar['date'], errors='coerce')
            df_valid = df_calendar.dropna(subset=['ê³µëª¨ì¼_dt'])
            
            traded = df_valid[df_valid['ê³µëª¨ì¼_dt'].dt.date < today.date()].sort_values(by='ê³µëª¨ì¼_dt', ascending=False).head(30)
            
            ret_sum, ret_cnt = 0, 0
            for _, row in traded.iterrows():
                try:
                    if not row['symbol'] or str(row['symbol']).lower() == 'none': continue
                    p_ipo = float(str(row.get('price','0')).replace('$','').split('-')[0])
                    tk = yf.Ticker(row['symbol'])
                    hist = tk.history(period='1d')
                    if not hist.empty and p_ipo > 0:
                        curr = hist['Close'].iloc[-1]
                        ret_sum += ((curr - p_ipo)/p_ipo)*100
                        ret_cnt += 1
                except: pass
            if ret_cnt > 0: data["ipo_return"] = ret_sum / ret_cnt
            
            future = df_valid[(df_valid['ê³µëª¨ì¼_dt'].dt.date >= today.date())]
            data["ipo_volume"] = len(future)

        try:
            vix = yf.Ticker("^VIX").history(period="1d")['Close'].iloc[-1]
            data['vix'] = vix
            spy = yf.Ticker("SPY")
            data['pe_ratio'] = spy.info.get('trailingPE', 24.5)
        except: pass
        
        prompt = f"í˜„ì¬ ì‹œì¥ ë°ì´í„°(VIX: {data['vix']:.2f}, IPOìˆ˜ìµë¥ : {data['ipo_return']:.1f}%)ë¥¼ ë°”íƒ•ìœ¼ë¡œ IPO íˆ¬ììì—ê²Œ ì£¼ëŠ” 3ì¤„ ì¡°ì–¸ (í•œêµ­ì–´)."
        try:
            ai_resp = model.generate_content(prompt).text
            supabase.table("analysis_cache").upsert([
                {"cache_key": "Global_Market_Dashboard_Tab2", "content": ai_resp, "updated_at": datetime.now().isoformat()}
            ], on_conflict="cache_key").execute()
        except: pass
        
        supabase.table("analysis_cache").upsert([
            {"cache_key": cache_key, "content": json.dumps(data), "updated_at": datetime.now().isoformat()}
        ], on_conflict="cache_key").execute()
        print("âœ… ê±°ì‹œ ì§€í‘œ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ Macro Update Fail: {e}")

# ==========================================
# [4] ë©”ì¸ ì‹¤í–‰ ë£¨í”„
# ==========================================
def main():
    print(f"ğŸš€ Worker Start: {datetime.now()}")
    
    df = get_target_stocks()
    if df.empty:
        print("ì¢…ëª©ì´ ì—†ì–´ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    # 1. ì¶”ì  ëª…ë‹¨ ì €ì¥
    print(f"ğŸ“ ì¶”ì  ëª…ë‹¨({len(df)}ê°œ) DB ë“±ë¡ ì¤‘...", end=" ")
    try:
        stock_list = []
        for _, row in df.iterrows():
            if row['symbol']:
                stock_list.append({
                    "symbol": row['symbol'], 
                    "name": row['name'],
                    "updated_at": datetime.now().isoformat()
                })
        supabase.table("stock_cache").upsert(stock_list, on_conflict="symbol").execute()
        print("âœ…")
    except Exception as e:
        print(f"âŒ ì‹¤íŒ¨: {e}")

    # 2. ê±°ì‹œ ì§€í‘œ ì—…ë°ì´íŠ¸
    update_macro_data(df)
    
    # 3. ê°œë³„ ì¢…ëª© ë£¨í”„
    total = len(df)
    for idx, row in df.iterrows():
        symbol = row.get('symbol')
        name = row.get('name')
        
        # [í•µì‹¬] None ë° ë¹ˆ ë¬¸ìì—´ ì¬í™•ì¸ (ì—ëŸ¬ ë°©ì§€)
        if not symbol or str(symbol).strip().upper() in ['NONE', 'NAN', ''] or str(symbol).lower() == 'none':
            continue
            
        print(f"[{idx+1}/{total}] {symbol} ì²˜ë¦¬ ì¤‘...", end=" ", flush=True)
        
        try:
            # AI ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìœ¼ë©´ ë¶„ì„ ìŠ¤í‚µ
            if not model:
                print("âš ï¸ AI ëª¨ë¸ ì—†ìŒ (ìŠ¤í‚µ)")
                continue

            # ê° íƒ­ ì‹¤í–‰ (ì—ëŸ¬ ë‚˜ë„ ê°œë³„ í•¨ìˆ˜ì—ì„œ ì²˜ë¦¬ë¨)
            run_tab0_analysis(symbol, name)
            run_tab1_analysis(symbol, name)
            run_tab4_analysis(symbol, name)
            
            # Tab 3 ì „ìš© ë°ì´í„° ìˆ˜ì§‘
            try:
                tk = yf.Ticker(symbol)
                info = tk.info
                growth = info.get('revenueGrowth', 0) * 100
                net_margin = info.get('profitMargins', 0) * 100
                roe = info.get('returnOnEquity', 0) * 100
                
                metrics_dict = {
                    "growth": f"{growth:.1f}%",
                    "net_margin": f"{net_margin:.1f}%",
                    "roe": f"{roe:.1f}%",
                    "pe": f"{info.get('forwardPE', 0):.1f}x"
                }
                run_tab3_analysis(symbol, name, metrics_dict)
            except:
                pass # ì¬ë¬´ ì •ë³´ ì—†ìœ¼ë©´ Tab3 ìŠ¤í‚µ
            
            print("âœ… ì™„ë£Œ")
            time.sleep(2) # Rate Limit ë°©ì§€ìš©
            
        except Exception as e:
            print(f"âŒ ì‹¤íŒ¨: {e}")
            time.sleep(1)
            continue # ë‹¤ìŒ ì¢…ëª©ìœ¼ë¡œ ê³„ì† ì§„í–‰
            
    print("ğŸ ëª¨ë“  ì‘ì—… ì¢…ë£Œ.")

if __name__ == "__main__":
    if not supabase:
        print("âŒ í•„ìˆ˜ ì„¤ì •(Supabase) ëˆ„ë½ìœ¼ë¡œ ì¤‘ë‹¨ë¨.")
    else:
        main()
